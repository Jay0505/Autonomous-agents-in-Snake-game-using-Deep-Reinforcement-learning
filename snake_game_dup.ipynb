{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev6 (SDL 2.0.10, python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import traceback\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pygame.locals import *\n",
    "# pygame.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Input, Flatten, Dense, Lambda, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "config = edict()\n",
    "\n",
    "config.CHECKPOINT_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/checkpoints/'\n",
    "config.NUM_EPOCHS     = 500\n",
    "config.BATCH_SIZE     = 64\n",
    "config.EPSILON        = 0.9\n",
    "config.BUFFER_SAMPLE_RATE = 0.8\n",
    "config.BUFFER_SAMPLE_RATE_DECAY_RATE = 0.1\n",
    "config.DISCOUNT_FACTOR = 0.99\n",
    "config.IMG_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/screenshots/'\n",
    "config.BUFFERS_NPY_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/npy_files/'\n",
    "config.FINAL_WEIGHTS_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/final_weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settings:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.screen_color = (100, 100, 100)\n",
    "        self.screen_width = 200\n",
    "        self.screen_height = 200\n",
    "        self.run_game = True\n",
    "        self.snake_nodes_group = []\n",
    "        \n",
    "        \n",
    "class Snake_Node:\n",
    "    def __init__(self, node_num, x, y, color, radius):\n",
    "        \n",
    "        self.snake_node_num = node_num\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.radius = radius\n",
    "        self.direction = 'up'\n",
    "        \n",
    "    def draw_snake_node(self, screen):\n",
    "#         snake_node = pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius)\n",
    "        snake_node = pygame.draw.rect(screen, self.color, (self.x, self.y, 10, 10), 1)\n",
    "        return snake_node\n",
    "    \n",
    "    \n",
    "    \n",
    "class Snake_Head:\n",
    "    def __init__(self, x, y, color, radius):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.radius = radius\n",
    "#         self.moving_direction = 'up'\n",
    "    \n",
    "    def draw_snake_head(self, screen):\n",
    "        snake_head = pygame.draw.rect(screen, self.color, (self.x, self.y, 10, 10))\n",
    "#         snake_head = pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius)\n",
    "        return snake_head\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Game_functions:\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_of_steps_in_curr_episode = 0\n",
    "        self.start_training_gap_period = False\n",
    "        self.is_apple_there = False\n",
    "        self.game_settings = settings()\n",
    "        self.divide_screen_into_segments()\n",
    "        self.num_of_snake_nodes = 0\n",
    "        self.snake_head_moving_direction = ' '\n",
    "        self.xy_list = []\n",
    "        self.radius = 10\n",
    "        self.rect_width = 5\n",
    "        self.rect_height = 5\n",
    "        self.full_reward = 0\n",
    "#         self.full_reward = False\n",
    "        self.img_count = 0\n",
    "        self.prev_distance = 0\n",
    "        self.new_game = True\n",
    "        self.score    = 10\n",
    "        self.img_dir  = config.IMG_DIR\n",
    "        \n",
    "        \n",
    "        self.create_dirs()\n",
    "        self.set_up_the_screen(True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def create_dirs(self):\n",
    "        if not os.path.exists(self.img_dir):\n",
    "            os.makedirs(self.img_dir)\n",
    "        \n",
    "        if not os.path.exists(config.CHECKPOINT_DIR):\n",
    "            os.makedirs(config.CHECKPOINT_DIR)\n",
    "        \n",
    "        if not os.path.exists(config.BUFFERS_NPY_DIR):\n",
    "            os.makedirs(config.BUFFERS_NPY_DIR)\n",
    "        \n",
    "        if not os.path.exists(config.FINAL_WEIGHTS_DIR):\n",
    "            os.makedirs(config.FINAL_WEIGHTS_DIR)\n",
    "            \n",
    "            \n",
    "    ####################################\n",
    "    \n",
    "    def divide_screen_into_segments(self):\n",
    "        self.segment_indices = []\n",
    "        for i in range(0, 200):\n",
    "            if i % 10 == 0:\n",
    "                self.segment_indices.append(i)\n",
    "                \n",
    "                \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def draw_snake_nodes_xy(self, from_list):\n",
    "        \n",
    "        if from_list:\n",
    "            for index, xy_tuple in enumerate(self.xy_list):\n",
    "                if index != 0:\n",
    "                    self.create_snake_head_or_apple(xy_tuple[0], xy_tuple[1], 5, False)\n",
    "                    pygame.display.update()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def get_new_xy_for_apple(self):\n",
    "        x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "        if (x, y) not in self.xy_list:\n",
    "            return x, y\n",
    "        else:\n",
    "            return self.get_new_xy_for_apple()\n",
    "        \n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def create_snake_head_or_apple(self, x, y, is_apple):\n",
    "        \n",
    "        if not is_apple:\n",
    "            color = (255,255,255)\n",
    "            \n",
    "            if self.num_of_snake_nodes != 0:\n",
    "                \n",
    "                snake_node_obj = Snake_Node(self.num_of_snake_nodes, x, y, color, self.radius)\n",
    "                snake_node = snake_node_obj.draw_snake_node(self.screen)\n",
    "                \n",
    "                \n",
    "            elif self.num_of_snake_nodes == 0:\n",
    "                snake_head_obj = Snake_Head(x, y, (0, 255, 0), self.radius)\n",
    "                self.snake_head = snake_head_obj.draw_snake_head(self.screen)\n",
    "\n",
    "                \n",
    "            self.num_of_snake_nodes = self.num_of_snake_nodes + 1\n",
    "            \n",
    "            if self.num_of_snake_nodes < 5:\n",
    "                pygame.time.wait(80)\n",
    "            else:\n",
    "                pygame.time.wait(10)\n",
    "            \n",
    "        if is_apple:\n",
    "            color = (255, 0, 0)\n",
    "            self.apple = pygame.draw.rect(self.screen, color, (x, y, 10, 10))\n",
    "#             self.apple = pygame.draw.circle(self.screen, color, (x, y), self.radius)\n",
    "            self.is_apple_there = True\n",
    "            self.apple_x = x\n",
    "            self.apple_y = y\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def start_a_new_game(self):\n",
    "#         print('start a new game')\n",
    "        if self.new_game:\n",
    "#             self.set_up_the_screen()\n",
    "            self.is_apple_there     = False\n",
    "            self.num_of_snake_nodes = 0\n",
    "            self.xy_list.clear()\n",
    "            self.screen.fill((100, 100, 100))\n",
    "            self.prev_distance      =  0\n",
    "            self.score              = 10\n",
    "            \n",
    "            x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "            self.xy_list.append((x, y))\n",
    "            self.draw_rect_at_new_location()\n",
    "            self.full_reward = 0\n",
    "            self.new_game = False\n",
    "            self.end_game = False\n",
    "            self.curr_reward = 0\n",
    "#             self.set_up_the_screen()\n",
    "\n",
    "    ####################################\n",
    "    \n",
    "    def check_if_snake_is_at_boundaries(self, new_x, new_y, direction):\n",
    "\n",
    "        if direction == 'up':\n",
    "            if new_y  < 0:\n",
    "                return True\n",
    "    \n",
    "\n",
    "        if direction == 'down':\n",
    "            if new_y  >= self.game_settings.screen_width:\n",
    "                return True\n",
    "    \n",
    "\n",
    "        if direction == 'left':\n",
    "            if new_x  < 0:\n",
    "                return True\n",
    "  \n",
    "\n",
    "        if direction == 'right':\n",
    "            if new_x  >= self.game_settings.screen_width:\n",
    "                return True\n",
    "        \n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####################################\n",
    "\n",
    "    def draw_rect_at_new_location(self):\n",
    "        \n",
    "        self.screen.fill((100, 100, 100))\n",
    "        self.num_of_snake_nodes = 0\n",
    "        \n",
    "        for xy_tuple in self.xy_list:        \n",
    "            self.create_snake_head_or_apple(xy_tuple[0], xy_tuple[1], False)\n",
    "    \n",
    "        \n",
    "        self.create_apple()\n",
    "        pygame.display.update()\n",
    "\n",
    "\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def get_new_x_y_for_moving(self, x, y, direction):\n",
    "        \n",
    "        if direction == 'up':\n",
    "            y = y - self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'down':\n",
    "            y = y + self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'left':\n",
    "            x = x - self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'right':\n",
    "            x = x + self.radius\n",
    "        \n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "#     ###################################\n",
    "    \n",
    "    def move_nodes(self, head_direction):\n",
    "        prev_tuple = (-1, -1)\n",
    "        curr_tuple = (-1, -1)\n",
    "        for index, xy_tuple in enumerate(self.xy_list):\n",
    "            if index == 0:\n",
    "                prev_tuple = xy_tuple\n",
    "            elif index != 0:\n",
    "                curr_tuple = self.xy_list[index]\n",
    "                self.xy_list[index] = prev_tuple\n",
    "                prev_tuple = curr_tuple\n",
    "        \n",
    "    \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def check_if_snake_ran_into_its_own_body(self):\n",
    "        \n",
    "        tuple_counter = Counter(self.xy_list)\n",
    "        if tuple_counter[self.xy_list[0]] != 1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    " \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def move_snake_head_new(self, direction):\n",
    "        \n",
    "        '''\n",
    "        First, get the new xy for the snake head to move\n",
    "        check whether the snake head is at the boundaries wrt new xy\n",
    "        if not, get new xy for all the snake nodes \n",
    "        update the xy_list with all the new xy values of both nodes and head\n",
    "        after updating, check, after moving, if the head bumped into its own body\n",
    "        '''\n",
    "#         end_game_in_curr_step = False\n",
    "        \n",
    "        x, y = self.xy_list[0][0], self.xy_list[0][1]\n",
    "        new_x, new_y = self.get_new_x_y_for_moving(x, y, direction)\n",
    "#         if new_x == -1 and new_y == -1:\n",
    "#             is_snake_at_boundary = True\n",
    "#         else:\n",
    "#             is_snake_at_boundary = False\n",
    "#         print(new_x, new_y)\n",
    "        is_snake_at_boundary = self.check_if_snake_is_at_boundaries(new_x, new_y, direction)\n",
    "\n",
    "        if not is_snake_at_boundary:\n",
    "#             print('not bound')\n",
    "            self.move_nodes(direction)\n",
    "            self.xy_list[0] = (new_x, new_y)\n",
    "            snake_ran_into_its_own_body = self.check_if_snake_ran_into_its_own_body()\n",
    "            if not snake_ran_into_its_own_body:\n",
    "                self.new_game = False\n",
    "#                 self.move_nodes(direction)\n",
    "                self.draw_rect_at_new_location()\n",
    "#                 pygame.display.update()\n",
    "#                 print(new_x_, new_y)\n",
    "            else:\n",
    "                '''\n",
    "                if the snake bumped into its own body, then a reward of -1 has to be given to the snake\n",
    "                '''\n",
    "                \n",
    "                self.full_reward = -1\n",
    "                self.new_game    = True\n",
    "#                 end_game_in_curr_step = True\n",
    "#                 self.end_game()\n",
    "#                 self.start_a_new_game()\n",
    "            \n",
    "\n",
    "        else:\n",
    "            '''\n",
    "            if the snake bumped into any boundary, then a reward of -1 has to be given to the snake\n",
    "            '''\n",
    "#             print('bundar')\n",
    "#             print(new_x, new_y)\n",
    "            self.full_reward = -1\n",
    "            self.new_game  = True\n",
    "#             end_game_in_curr_step = True\n",
    "#             self.end_game()\n",
    "#             self.start_a_new_game()\n",
    "\n",
    "        \n",
    "#         return end_game_in_curr_step\n",
    "        \n",
    "    \n",
    "\n",
    "    ####################################\n",
    "    \n",
    "    def create_apple(self):\n",
    "        \n",
    "        if not self.is_apple_there:\n",
    "            x, y = self.get_new_xy_for_apple()\n",
    "#             x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "            \n",
    "            self.create_snake_head_or_apple(x, y, True)\n",
    "        \n",
    "        if self.is_apple_there:\n",
    "            self.create_snake_head_or_apple(self.apple_x, self.apple_y, True)\n",
    "            \n",
    "        pygame.display.update()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    '''\n",
    "    if an action is supplied (direction) and in that direction, if there is a node in that direction, then stop moving it\n",
    "    \n",
    "    '''\n",
    "    def check_whether_to_move_nodes_or_not(self, direction):\n",
    "        if direction == 'up':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] and self.xy_list[0][1] == self.xy_list[1][1] + self.radius:\n",
    "                return False\n",
    "        \n",
    "        elif direction == 'down':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] and self.xy_list[0][1] == self.xy_list[1][1] - self.radius:\n",
    "                return False\n",
    "        \n",
    "        elif direction == 'left':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] + self.radius and self.xy_list[0][1] == self.xy_list[1][1]:\n",
    "                return False\n",
    "            \n",
    "        elif direction == 'right':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] - self.radius and self.xy_list[0][1] == self.xy_list[1][1]:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    def get_new_xy_for_new_node_after_eating_apple(self):\n",
    "        \n",
    "        last_node_x, last_node_y = self.xy_list[-1][0], self.xy_list[-1][1]\n",
    "        new_x, new_y = -1, -1\n",
    "        \n",
    "        if last_node_x + self.radius < self.game_settings.screen_width:\n",
    "            if (last_node_x + self.radius, last_node_y) not in self.xy_list: \n",
    "                new_x = last_node_x + self.radius\n",
    "                new_y = last_node_y\n",
    "        \n",
    "        elif last_node_x - self.radius > 0:\n",
    "            if (last_node_x - self.radius, last_node_y) not in self.xy_list:\n",
    "                new_x = last_node_x - self.radius\n",
    "                new_y = last_node_y\n",
    "        \n",
    "        \n",
    "        elif last_node_y - self.radius > 0 :\n",
    "            if (last_node_x, last_node_y - self.radius) not in self.xy_list: \n",
    "                new_x = last_node_x\n",
    "                new_y = last_node_y -self.radius5\n",
    "            \n",
    "        elif last_node_y + self.radius < self.game_settings.screen_width:\n",
    "            if (last_node_x, last_node_y + self.radius) not in self.xy_list:\n",
    "                new_x = last_node_x\n",
    "                new_y = last_node_y + self.radius\n",
    "            \n",
    "        \n",
    "        return new_x, new_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    def add_just_eaten_apple_to_the_snake_end(self):\n",
    "        \n",
    "        new_node_x, new_node_y = self.get_new_xy_for_new_node_after_eating_apple()\n",
    "        self.xy_list.append((new_node_x, new_node_y))\n",
    "        self.is_apple_there = False\n",
    "        self.draw_rect_at_new_location()\n",
    "        self.start_training_gap_period = True\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    '''\n",
    "    if apple's xy and snake_head's xy (first value in xy_list), then we consider that snake has eaten apple\n",
    "    '''\n",
    "    def is_apple_eaten(self):\n",
    "        \n",
    "        if self.is_apple_there:\n",
    "            if self.apple_x == self.xy_list[0][0] and self.apple_y == self.xy_list[0][1]:\n",
    "                '''\n",
    "                if apple is eaten, a full reward of 1 has to be given to the snake\n",
    "                '''\n",
    "                self.full_reward = 1\n",
    "                self.score = self.score + 10\n",
    "                self.add_just_eaten_apple_to_the_snake_end()\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def check_if_snake_moved_closer_to_apple(self):\n",
    "        \n",
    "        snake_head_xy = self.xy_list[0]\n",
    "        apple_xy      = (self.apple_x, self.apple_y)\n",
    "        \n",
    "        curr_distance = math.sqrt( ((snake_head_xy[0] - apple_xy[0]) ** 2) + ((snake_head_xy[1] - apple_xy[1]) ** 2))\n",
    "        \n",
    "        curr_length = self.score\n",
    "        ratio = (curr_length + self.prev_distance) / (curr_length + curr_distance)\n",
    "        reward = math.log(ratio, curr_length) # calculate logarithm base curr_length of ratio\n",
    "        if reward <= -1:\n",
    "            reward = reward + 1\n",
    "        elif reward >= 1:\n",
    "            reward = reward - 1\n",
    "        self.prev_distance = curr_distance\n",
    "        return reward\n",
    "#             if curr_distance < self.prev_distance:\n",
    "#                 return True\n",
    "#             else: \n",
    "#                 False\n",
    "#             self.prev_distance = curr_distance\n",
    "        \n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def get_reward(self):\n",
    "        '''\n",
    "        -- if snake_head moved towards apple, reward = 0.2\n",
    "        --                            if not, reward = -0.2\n",
    "        --- if snake bumped into its own body or bumped into boundaries, reward = -1\n",
    "        --- if snake eats apple, reward = 1\n",
    "        --- if snake cannot move, then reward = -0.1\n",
    "        '''\n",
    "        if self.full_reward == 0:\n",
    "            distance_reward = self.check_if_snake_moved_closer_to_apple()\n",
    "            return distance_reward\n",
    "        \n",
    "        else:\n",
    "            return self.full_reward\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    def get_curr_state_of_the_game(self):\n",
    "        \n",
    "        '''\n",
    "        -- Stacking last 4 screenshots of the image as one\n",
    "        -- if the num of screenshots is less than 4, then the last screenshot has to be appended \n",
    "            required num of times\n",
    "        --- if the num of screenshots is greater than 4, then the recent last 4 screenshots have to be \n",
    "            appended\n",
    "        '''\n",
    "#         print('  previous')\n",
    "#         for path in self.curr_screenshots_paths:\n",
    "#             print(path)\n",
    "        \n",
    "#         print(' ')\n",
    "        self.curr_screenshots_paths.clear()\n",
    "        img_ids = []\n",
    "        if self.img_count < 4 and self.img_count > 0:\n",
    "            for id_ in range(self.img_count):\n",
    "                img_ids.append(id_)\n",
    "            remaining = 4 - self.img_count\n",
    "            for _ in range(remaining):\n",
    "                img_ids.append(img_ids[-1])\n",
    "\n",
    "        elif self.img_count >= 4:\n",
    "            for id_ in range(1, 5):\n",
    "                img_ids.append(self.img_count - id_)\n",
    "        \n",
    "            img_ids.reverse()\n",
    "        \n",
    "        for id_ in img_ids:\n",
    "            self.curr_screenshots_paths.append(self.img_dir + str(id_) + '.jpg')\n",
    "        reward = self.get_reward()        \n",
    "        end_game = self.new_game\n",
    "        \n",
    "#         self.curr_screenshot_path = curr_screenshot_path\n",
    "        self.curr_reward = reward\n",
    "        self.end_game    = end_game\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    ###################################    \n",
    "    '''\n",
    "    -- if we started the game newly then is_game_just_started is set to True.\n",
    "    -- if game ended because of the snake bumping into itself or into boundaries, then we have to end the current game and have to \n",
    "        start a new game. In this case, is_game_just_started is set to False\n",
    "    '''\n",
    "    def set_up_the_screen(self, is_game_just_started):\n",
    "        pygame.init()\n",
    "        pygame.display.init()\n",
    "        self.screen = pygame.display.set_mode((self.game_settings.screen_width, self.game_settings.screen_height))\n",
    "        pygame.display.flip()\n",
    "        self.start_a_new_game()\n",
    "        \n",
    "        if is_game_just_started:\n",
    "#             pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "            self.img_count = self.img_count + 1\n",
    "            self.curr_screenshots_paths = []\n",
    "            self.curr_reward = 0\n",
    "            self.end_game = False\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def end_the_game_and_start_a_new_one(self):\n",
    "    \n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "        exit()\n",
    "        self.new_game = True\n",
    "        self.set_up_the_screen(False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def end_the_game(self):\n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "        exit()\n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def run(self, action):\n",
    "#         while self.game_settings.run_game:\n",
    "        try:\n",
    "            \n",
    "            apple_eaten = False\n",
    "            events = pygame.event.get()\n",
    "            \n",
    "            for event in events:\n",
    "                if event.type == pygame.KEYDOWN:\n",
    "                    if event.key == pygame.K_x:\n",
    "                        self.game_settings.run_game = False\n",
    "                        pygame.display.quit()\n",
    "                        pygame.quit()\n",
    "                        exit()\n",
    "                    \n",
    "                \n",
    "            if self.num_of_snake_nodes == 1:\n",
    "                move_nodes = True\n",
    "\n",
    "            keys = pygame.key.get_pressed()\n",
    "            \n",
    "            if keys[pygame.K_x]:\n",
    "                self.game_settings.run_game = False\n",
    "                pygame.display.quit()\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "            ############\n",
    "\n",
    "            if action == 'up':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "\n",
    "\n",
    "            ##############\n",
    "\n",
    "            elif action == 'down':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "\n",
    "\n",
    "            ##############\n",
    "\n",
    "            elif action == 'left':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ###########\n",
    "\n",
    "            elif action == 'right':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "    \n",
    "            if not self.new_game:\n",
    "                self.is_apple_eaten()\n",
    "                pygame.display.flip()\n",
    "#             if not self.end_game:\n",
    "                pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "                self.img_count = self.img_count + 1\n",
    "            self.get_curr_state_of_the_game()\n",
    "#             else:\n",
    "#                 self.end_the_game()\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# game_functions = Game_functions()\n",
    "# # game_functions.run('test')\n",
    "# for i in range(200):\n",
    "#     actions = ['right', 'right', 'right', 'left']\n",
    "#     action_index = random.randint(0, 3)\n",
    "#     action = actions[action_index]\n",
    "#     game_functions.run(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Q_values_approximator_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def normalize_to_range_01(self, img):\n",
    "        return tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    def get_q_values(self):\n",
    "        input_data = Input(shape = (64, 64, 12))\n",
    "        data = Lambda(self.normalize_to_range_01)(input_data)\n",
    "        data = Conv2D(filters = 32, kernel_size = 7, strides = (4, 4), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Conv2D(filters = 64, kernel_size = 5, strides = (2, 2), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Conv2D(filters = 128, kernel_size = 3, strides = (2, 2), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Flatten()(data)\n",
    "        data = Dense(512)(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Dense(4)(data)\n",
    "        \n",
    "        self.model = tf.keras.Model(input_data, data)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.game_controls = Game_functions()\n",
    "        self.training_gap_steps = 0\n",
    "        self.experiences_buffer_1   = []\n",
    "        self.experiences_buffer_2 = []\n",
    "        self.observation_period_threshold = 50000\n",
    "        self.num_of_steps_completed_in_obv_period = 0\n",
    "        self.actions = ['up', 'down', 'right', 'left']\n",
    "        \n",
    "        q_values_predictor = Q_values_approximator_model()\n",
    "        q_values_predictor.get_q_values()\n",
    "        self.q_values_pred_model = q_values_predictor.model\n",
    "        self.model_optimizer = Adam(learning_rate = 0.001)\n",
    "        self.checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "                                              optimizer = self.model_optimizer,\n",
    "                                              model = self.q_values_pred_model \n",
    "                                             )\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, \n",
    "                                                            directory = config.CHECKPOINT_DIR,\n",
    "                                                            max_to_keep = 3)\n",
    "        self.mse_loss = MeanAbsoluteError()\n",
    "        self.buffers_max_len = self.observation_period_threshold\n",
    "        self.from_index_to_add_exp_buffer_1 = -1\n",
    "        self.from_index_to_add_exp_buffer_2 = -1\n",
    "        \n",
    "    ############################################\n",
    "        \n",
    "    def preprocess_and_stack_images(self, curr_game_images_paths):\n",
    "#         print(' ')\n",
    "#         print(curr_game_images_paths)\n",
    "#         print(' ')\n",
    "        images = []\n",
    "        for image_path in curr_game_images_paths:\n",
    "#             print(image_path)\n",
    "            image = cv2.resize(cv2.imread(image_path), (64, 64))\n",
    "            images.append(image)\n",
    "        \n",
    "        stacked_images = np.concatenate((images[0], images[1], images[2], images[3]), axis = 2)\n",
    "        return stacked_images\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    '''\n",
    "    After deciding upon action to be taken, run the game for one step\n",
    "    Then, collect the next state images paths, reward received and whether the next state is terminal\n",
    "    '''\n",
    "    def perform_a_step_in_an_episode(self, action):\n",
    "        \n",
    "        self.game_controls.run(action)\n",
    "        game_imgs_paths_after_action = self.game_controls.curr_screenshots_paths \n",
    "        reward_after_action = self.game_controls.curr_reward\n",
    "        end_game_after_action = self.game_controls.end_game\n",
    "        start_training_gap_period = self.game_controls.start_training_gap_period\n",
    "\n",
    "        return game_imgs_paths_after_action, reward_after_action, end_game_after_action, start_training_gap_period\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def determing_num_of_training_gap_steps_after_snake_eating_apple(self):\n",
    "        length_of_snake = self.game_controls.score \n",
    "        k = 10\n",
    "        p = 0.4\n",
    "        q = 0.2\n",
    "        if length_of_snake <= k:\n",
    "            self.training_gap_steps = 6\n",
    "        elif length_of_snake > k:\n",
    "            self.training_gap_steps = math.ceil((p * length_of_snake) + q)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def check_if_buffers_reached_their_maximum_capacity(self, buffer_num):\n",
    "        \n",
    "        if buffer_num == 1: #and len(self.experiences_buffer_1) == self.buffers_max_len:\n",
    "            if self.from_index_to_add_exp_buffer_1 == -1 or self.from_index_to_add_exp_buffer_1 > self.buffers_max_len - 1:\n",
    "                self.from_index_to_add_exp_buffer_1 = 0\n",
    "\n",
    "        \n",
    "        elif buffer_num == 2: #and len(self.experiences_buffer_2) == self.buffers_max_len:\n",
    "            if self.from_index_to_add_exp_buffer_2 == -1 or self.from_index_to_add_exp_buffer_2 > self.buffers_max_len - 1:\n",
    "                self.from_index_to_add_exp_buffer_2 = 0\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def save_buffer_experiences_as_npy_files_periodically(self):\n",
    "        npy_files = glob.glob(config.BUFFERS_NPY_DIR + '*')\n",
    "        for file in npy_files:\n",
    "            os.remove(file)\n",
    "#         print(len(self.experiences_buffer_1), len(self.experiences_buffer_2))\n",
    "        np.save(config.BUFFERS_NPY_DIR + 'buffer_1_npy.npy', self.experiences_buffer_1)\n",
    "        np.save(config.BUFFERS_NPY_DIR + 'buffer_2_npy.npy', self.experiences_buffer_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    '''\n",
    "    --- Get an action and run the game as per the action\n",
    "    --- Now, record the updated state of the game by getting the curr screenshot of the screen, \n",
    "         current reward and also whether the current state resulted in quitting game which happens\n",
    "         when snake bumps into boundaries or ran into itself.\n",
    "\n",
    "    '''\n",
    "    def add_experiences_to_buffers_after_running_game_for_one_step(self, action, curr_state_imgs_paths, \n",
    "                                                                               next_state_imgs_paths, reward_after_action, end_game):\n",
    "        \n",
    "#         print('  before ' + str(self.from_index_to_add_exp_buffer_1) +' ' + str(self.from_index_to_add_exp_buffer_2))\n",
    "        self.check_if_buffers_reached_their_maximum_capacity(1)\n",
    "        self.check_if_buffers_reached_their_maximum_capacity(2)\n",
    "\n",
    "        buffer_1_len = len(self.experiences_buffer_1)\n",
    "        buffer_2_len = len(self.experiences_buffer_2)\n",
    "#         print('  after ' + str(self.from_index_to_add_exp_buffer_1) +' ' + str(self.from_index_to_add_exp_buffer_2))\n",
    "#         for path in curr_state_imgs_paths:\n",
    "#             print('   ' + str(path))\n",
    "        \n",
    "#         print(' ')\n",
    "#         print(' ')\n",
    "        if reward_after_action <= 0:\n",
    "            \n",
    "            if buffer_1_len == self.buffers_max_len:\n",
    "                self.experiences_buffer_1[self.from_index_to_add_exp_buffer_1] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "            elif buffer_1_len < self.buffers_max_len - 1:\n",
    "                self.experiences_buffer_1.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "            \n",
    "            self.from_index_to_add_exp_buffer_1 = self.from_index_to_add_exp_buffer_1 + 1\n",
    "            \n",
    "#             if self.from_index_to_add_exp_buffer_1 == -1:\n",
    "#                 self.experiences_buffer_1.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "#             else:\n",
    "#                 self.experiences_buffer_1[self.from_index_to_add_exp_buffer_1] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "#                 self.from_index_to_add_exp_buffer_1 = self.from_index_to_add_exp_buffer_1 + 1\n",
    "        \n",
    "        else:\n",
    "            if buffer_2_len == self.buffers_max_len:\n",
    "                self.experiences_buffer_2[self.from_index_to_add_exp_buffer_2] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "            elif buffer_2_len < self.buffers_max_len:\n",
    "                self.experiences_buffer_2.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "            \n",
    "            self.from_index_to_add_exp_buffer_2 = self.from_index_to_add_exp_buffer_2 + 1\n",
    "            \n",
    "            \n",
    "            \n",
    "#             if self.from_index_to_add_exp_buffer_2 == -1:\n",
    "#                 self.experiences_buffer_2.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "#             else:\n",
    "#                 self.experiences_buffer_2[self.from_index_to_add_exp_buffer_2] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "#                 self.from_index_to_add_exp_buffer_2 = self.from_index_to_add_exp_buffer_2 + 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def start_exploration_in_observation_period(self):\n",
    "        \n",
    "        '''If not resuming (if we are staring now), that means, we have just started and there is no current state\n",
    "        Therefore, for two steps, choose a random action and then carry on forward'''\n",
    "        if self.game_controls.img_count == 1:\n",
    "            steps_taken = 0\n",
    "            while steps_taken < 5:\n",
    "                \n",
    "                action = self.actions[random.randint(0, 3)]\n",
    "                self.perform_a_step_in_an_episode(action)\n",
    "                \n",
    "                steps_taken = steps_taken + 1\n",
    "            \n",
    "\n",
    "              \n",
    "        num_of_training_gap_steps_completed = 0\n",
    "        enter_training_gap_period = False\n",
    "        \n",
    "        self.game_controls.get_curr_state_of_the_game()\n",
    "        curr_state_imgs_paths = self.game_controls.curr_screenshots_paths.copy()\n",
    "        curr_reward           = self.game_controls.curr_reward\n",
    "        end_game              = self.game_controls.end_game\n",
    "        start_training_gap    = self.game_controls.start_training_gap_period\n",
    "#         curr_state           = self.preprocess_and_stack_images(curr_game_imgs_paths)\n",
    "\n",
    "        while self.num_of_steps_completed_in_obv_period < self.observation_period_threshold and not end_game:\n",
    "        \n",
    "            \n",
    "            '''\n",
    "            -- so, when the snake eats an apple, then we should immediately enter into a training_gap_period during which no experiences are\n",
    "                stored into experience buffers.\n",
    "            \n",
    "            -- if start_training_gap and enter_training_gap_period == False, then we haven't entered the training_gap and therefore set\n",
    "                enter_training_gap_period = True\n",
    "            \n",
    "            -- if not start_training_gap, then add experiences to the buffer. if in training_gap_period, then just perform single step in the game\n",
    "                without storing experiences in the experience buffers. Also, increase the number of steps completed in trainig_gap_period\n",
    "            \n",
    "            -- if the num_of_steps in training_gap is equal to the pre-determined num_of_steps in training_gap_period, then exit training_gap_period\n",
    "                by setting enter_training_gap_period = False and self.game_controls.start_training_gap_period = False\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            if (self.num_of_steps_completed_in_obv_period % 5000 == 0 or self.num_of_steps_completed_in_obv_period == self.observation_period_threshold - 1) and self.num_of_steps_completed_in_obv_period > 0:\n",
    "                self.save_buffer_experiences_as_npy_files_periodically()\n",
    "                print('npy files saved and ' + str(self.num_of_steps_completed_in_obv_period) + ' steps completed')\n",
    "\n",
    "                \n",
    "                \n",
    "            if start_training_gap and not enter_training_gap_period:\n",
    "                enter_training_gap_period = True\n",
    "                self.determing_num_of_training_gap_steps_after_snake_eating_apple()\n",
    "            \n",
    "            \n",
    "            if enter_training_gap_period and (num_of_training_gap_steps_completed == self.training_gap_steps - 1):\n",
    "                enter_training_gap_period = False\n",
    "                self.game_controls.start_training_gap_period = False\n",
    "            \n",
    "            action = self.actions[random.randint(0, 3)]\n",
    "            \n",
    "            next_state_imgs_paths, reward_after_action, end_game, start_training_gap = self.perform_a_step_in_an_episode(action)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if not enter_training_gap_period:\n",
    "\n",
    "    \n",
    "                self.add_experiences_to_buffers_after_running_game_for_one_step(action, curr_state_imgs_paths.copy(), \n",
    "                                                                               self.game_controls.curr_screenshots_paths.copy(), \n",
    "                                                                                reward_after_action, end_game)  \n",
    "            elif enter_training_gap_period:\n",
    "                num_of_training_gap_steps_completed = num_of_training_gap_steps_completed + 1\n",
    "\n",
    "            curr_state_imgs_paths = next_state_imgs_paths.copy()\n",
    "            self.num_of_steps_completed_in_obv_period = self.num_of_steps_completed_in_obv_period + 1\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "        \n",
    "    def restore_checkpoint(self):\n",
    "\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print('restored checkpoint successfully at epoch ' + str(self.checkpoint.curr_epoch.numpy()))\n",
    "        else:\n",
    "            print('No checkpoint restoration')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    def epsilon_greedy_policy_for_action(self, curr_state_imgs_paths):\n",
    "        if random.random() < config.EPSILON:\n",
    "            return self.actions[random.randint(0, 3)]\n",
    "        else:\n",
    "            curr_state_imgs = self.preprocess_and_stack_images(curr_state_imgs_paths)\n",
    "            q_values = self.checkpoint.model(np.expand_dims(curr_state_imgs, axis = 0), training = True)\n",
    "            return self.actions[np.argmax(q_values.numpy()[0])]\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    def adjust_buffer_sample_rate(self, epoch):\n",
    "        if epoch % 1000 == 0:\n",
    "            decay_value = config.BUFFER_SAMPLE_RATE * config.BUFFER_SAMPLE_RATE_DECAY_RATE\n",
    "            new_buffer_sample_rate = config.BUFFER_SAMPLE_RATE - decay_value\n",
    "            if not new_buffer_sample_rate > 0.5:\n",
    "                config.BUFFER_SAMPLE_RATE = new_buffer_sample_rate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def sample_mini_batches_from_experience_buffers(self):\n",
    "        \n",
    "        experience_1_buffer_length = len(self.experiences_buffer_1)\n",
    "        experience_2_buffer_length = len(self.experiences_buffer_2)\n",
    "        required_num_of_samples_from_buffer_1 = int(64 * config.BUFFER_SAMPLE_RATE)\n",
    "        \n",
    "        if experience_1_buffer_length < required_num_of_samples_from_buffer_1:\n",
    "            num_samples_from_buffer_1 = experience_1_buffer_length\n",
    "        else:\n",
    "            num_samples_from_buffer_1 = int(64 * config.BUFFER_SAMPLE_RATE)\n",
    "            \n",
    "        num_samples_from_buffer_2 = 64 - num_samples_from_buffer_1\n",
    "\n",
    "        random_samples_from_buffer_1 = random.sample(self.experiences_buffer_1, num_samples_from_buffer_1)\n",
    "        random_samples_from_buffer_2 = random.sample(self.experiences_buffer_2, num_samples_from_buffer_2)\n",
    "\n",
    "        return random_samples_from_buffer_1, random_samples_from_buffer_2\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    def get_target_labels_for_samples(self, buffer_samples):\n",
    "        '''\n",
    "        experience[0] = curr_State_imgs_paths\n",
    "        experience[1] = action [This is a text 'up', 'down', 'left', 'right']\n",
    "        experience[2] = reward_after_action\n",
    "        experience[3] = next_state_imgs_paths\n",
    "        experience[4] = end_game\n",
    "        '''\n",
    "\n",
    "        \n",
    "        temp_labels = []\n",
    "        for experience in buffer_samples:\n",
    "            if experience[4]:\n",
    "                temp_labels.append([True, experience[0], experience[2]])\n",
    "            \n",
    "            else:\n",
    "                temp_labels.append([False, experience[3], experience[2]])\n",
    "        \n",
    "        return temp_labels\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    '''\n",
    "    -- In total we would get a total of 64 experiences sampled from buffer experiences.\n",
    "    -- Now, for actual labels, we have run through all the screenshots of the game through the model.\n",
    "    -- In other words, either we should run the model for each screenshots in all the 64 experiences separately, or\n",
    "    -- we can group together all the images in all the experiences as one and the we can run the model on this single set of all images.\n",
    "    -- In the later case, the shape of the input to the model would be, [64, 64, 64, 12]\n",
    "    -- 64 - total num of experiences (each experience will have one of the screenshots)\n",
    "        64 , 64 - would be the size of the each image\n",
    "        12 - here, each screenshot will have 3 channels and we consider recent 4 screenshots. If we concatenate all the 4 screenshots, \n",
    "        then the number of channels will be 12\n",
    "    '''\n",
    "    def get_actual_labels_for_samples(self, buffer_samples):\n",
    "        actual_labels = []\n",
    "        images = []\n",
    "        action_values = []\n",
    "        for experience in buffer_samples:\n",
    "            curr_state_imgs_paths = experience[0]\n",
    "            action = experience[1]\n",
    "            action_index = self.actions.index(action)\n",
    "            action_values.append(action_index)\n",
    "            curr_state_imgs = self.preprocess_and_stack_images(curr_state_imgs_paths)\n",
    "            images.append(curr_state_imgs)\n",
    "          \n",
    "        return images, action_values\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def loss_function(self, target_labels, actual_labels):\n",
    "        return np.square(np.asarray(target_labels) - np.asarray(actual_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def train_step(self, buffer_samples):\n",
    "        \n",
    "            \n",
    "        with tf.GradientTape(persistent = True) as params_tape:\n",
    "            target_label_values_img_paths = self.get_target_labels_for_samples(buffer_samples)\n",
    "            images, action_values = self.get_actual_labels_for_samples(buffer_samples)\n",
    "            \n",
    "            target_label_values_for_samples = []\n",
    "            actual_label_values_for_samples = []\n",
    "            '''\n",
    "            entry is list of three values:\n",
    "            either\n",
    "                1. bool value telling second value is a label value (in this case, True)\n",
    "                2. a label value (reward_after_action)\n",
    "                3. -1\n",
    "            \n",
    "            or\n",
    "                1. bool value telling we have to calculate the label value using next_state_img_paths (in this case, False)\n",
    "                2. next_state_img_paths\n",
    "                3. reward_after_action\n",
    "            '''\n",
    "            # calculation target_values\n",
    "            for entry in target_label_values_img_paths:\n",
    "                if entry[0]: # if game_ended at this step then label = reward\n",
    "                    target_label_values_for_samples.append(entry[2])\n",
    "                \n",
    "                else: # else label = reward + gamma * max(model(images, action))\n",
    "                    next_state_imgs = self.preprocess_and_stack_images(entry[1])\n",
    "                    q_values_of_actions = self.checkpoint.model(np.expand_dims(next_state_imgs, axis = 0), training = True)\n",
    "                    \n",
    "#                     target_value = entry[2] + (config.DISCOUNT_FACTOR * np.max(q_values_of_actions.numpy()[0]))\n",
    "                    target_value = entry[2] + (config.DISCOUNT_FACTOR * tf.math.reduce_max(q_values_of_actions))\n",
    "                    target_label_values_for_samples.append(target_value)\n",
    "            \n",
    "            \n",
    "            # calculating actual labels\n",
    "            q_values_of_actions_a = self.checkpoint.model(np.asarray(images), training = True)\n",
    "#             q_values_of_actions_numpy = q_values_of_actions_a\n",
    "        \n",
    "            for index, q_values in enumerate(q_values_of_actions_a):\n",
    "#             for index, q_values in enumerate(q_values_of_actions_numpy):\n",
    "                actual_label_values_for_samples.append(q_values[action_values[index]])\n",
    "\n",
    "#             if self.count == 0:\n",
    "#                 print(type(target_label_values_for_samples))\n",
    "#                 print(target_label_values_for_samples)\n",
    "#                 print('---------------')\n",
    "#                 print(type(actual_label_values_for_samples))\n",
    "#                 print(actual_label_values_for_samples)\n",
    "                                                       \n",
    "            loss = self.mse_loss(tf.convert_to_tensor(actual_label_values_for_samples), \n",
    "                                 tf.convert_to_tensor(target_label_values_for_samples))\n",
    "            \n",
    "        model_gradients = params_tape.gradient(tf.cast(loss, tf.float32), self.checkpoint.model.trainable_variables)\n",
    "        \n",
    "        self.checkpoint.optimizer.apply_gradients(zip(model_gradients, self.checkpoint.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "                \n",
    "        \n",
    "    \n",
    "\n",
    "    ############################################\n",
    "    \n",
    "    '''\n",
    "    Now, when we resume game after a pause or a stop, then we have to know how many number of steps completed in the \n",
    "    observation period so that we can resume recording experiences from that step onwards. To achieve this, before starting\n",
    "    recording experiences in observation period, we should how many number of experiences are there in each buffer which\n",
    "    we can know by reading the npy files of the buffers stored in config.BUFFERS_NPY_DIR directory. If we add the number\n",
    "    of experiences in both the npy files, then we can know how many total number of steps are completed in observation \n",
    "    period, as each experience is recorded after completing one individual game step.\n",
    "    '''\n",
    "    \n",
    "    def check_the_num_of_steps_completed_in_observation_period(self):\n",
    "        num_of_steps_completed_in_obsv_period = 0\n",
    "        files = glob.glob(config.BUFFERS_NPY_DIR + '*')\n",
    "        if len(files) != 0:\n",
    "            for file in files:\n",
    "                \n",
    "                buffer_experiences = np.load(file, allow_pickle = True)\n",
    "                if 'buffer_1_npy' in file:\n",
    "                    self.experiences_buffer_1 = list(buffer_experiences)\n",
    "                    self.from_index_to_add_exp_buffer_1 = len(self.experiences_buffer_1)\n",
    "                \n",
    "                else:\n",
    "                    self.experiences_buffer_2 = list(buffer_experiences)\n",
    "                    self.from_index_to_add_exp_buffer_2 = len(self.experiences_buffer_2)\n",
    "                num_of_steps_completed_in_obsv_period = num_of_steps_completed_in_obsv_period + len(buffer_experiences)\n",
    "                \n",
    "            \n",
    "            \n",
    "            return num_of_steps_completed_in_obsv_period \n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def check_for_in_screenshots_and_get_images_count(self):\n",
    "        files = os.listdir(self.game_controls.img_dir)\n",
    "        files = [file for file in files if 'DS' not in file]\n",
    "        if len(files) != 0:\n",
    "            '''Sort the image names using the integer part'''\n",
    "            files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "            recent_img_name = files[-1]\n",
    "            match_object = re.search('\\D', recent_img_name)\n",
    "            num = int(recent_img_name[0:match_object.start()])\n",
    "            return num\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    def observation_period(self):\n",
    "        '''\n",
    "        For the first 50000 seteps, just let the agent choose random actions and explore very\n",
    "        extensively so tha it could have a vast experience buffer\n",
    "        '''\n",
    "#         try:\n",
    "        self.game_controls.img_count = self.check_for_in_screenshots_and_get_images_count()\n",
    "        obsv_period_steps_completed = self.check_the_num_of_steps_completed_in_observation_period()\n",
    "        \n",
    "        if self.game_controls.img_count > 45000:\n",
    "            self.num_of_steps_completed_in_obv_period = self.observation_period_threshold - 1\n",
    "            \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            if self.game_controls.img_count > obsv_period_steps_completed:\n",
    "                self.num_of_steps_completed_in_obv_period = self.game_controls.img_count\n",
    "            else:\n",
    "                self.num_of_steps_completed_in_obv_period = obsv_period_steps_completed\n",
    "\n",
    "            print('num of steps completed are ' + str(self.num_of_steps_completed_in_obv_period))\n",
    "            if not self.num_of_steps_completed_in_obv_period == self.observation_period_threshold - 1:\n",
    "                self.start_exploration_in_observation_period()\n",
    "                \n",
    "                while self.num_of_steps_completed_in_obv_period < self.observation_period_threshold:\n",
    "                    self.game_controls.end_the_game_and_start_a_new_one()\n",
    "                    self.start_exploration_in_observation_period()\n",
    "\n",
    "#                 self.game_controls.end_the_game_and_start_a_new_one()\n",
    "        print(' ')\n",
    "        print(' final count is ' + str(self.game_controls.img_count))\n",
    "#         self.game_controls.self.game_controls.end_the_game_and_start_a_new_one()()\n",
    "        print('exploration period ended')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    If snake failed to eat any apple in the past P steps, it receives a negative as a punishment\n",
    "    '''\n",
    "#     def check_and_apply_negative_reward_if_snake_not_eat_apple_for_p_steps(self):\n",
    "        \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        start = True\n",
    "        imgs_count = self.check_for_in_screenshots_and_get_images_count()\n",
    "#         obsv_period_steps_completed = self.check_the_num_of_steps_completed_in_observation_period()\n",
    "        \n",
    "#         print(self.from_index_to_add_exp_buffer_1, self.from_index_to_add_exp_buffer_2)\n",
    "        \n",
    "        self.restore_checkpoint()\n",
    "        epochs_completed = self.checkpoint.curr_epoch.numpy()\n",
    "        epochs_remaining = config.NUM_EPOCHS - epochs_completed\n",
    "        \n",
    "#         self.game_controls.end_the_game()\n",
    "#         self.game_controls    = Game_functions()\n",
    "        self.game_controls.img_count = imgs_count\n",
    "        loss_log = tf.keras.metrics.Mean('perc_loss', dtype = tf.float32)\n",
    "        for epoch in range(epochs_remaining):\n",
    "            \n",
    "            \n",
    "            print('epoch ' + str(epoch))\n",
    "            \n",
    "            self.game_controls.end_the_game_and_start_a_new_one()\n",
    "            curr_epoch = self.checkpoint.curr_epoch.numpy()\n",
    "            \n",
    "            '''\n",
    "            When observation period ended and when we start training, at the start of each epoch, we are doing end_the_game_and_start_a_new_game() leaving\n",
    "            curr_state_of_the_game as it is. In other words, when observation period ended and if we are starting with 0th epoch, \n",
    "            end_game = Fase,\n",
    "            reward = -1 (for bumping into boundaries or into itself)\n",
    "            and so on.\n",
    "            \n",
    "            Therefore, \n",
    "            '''\n",
    "            \n",
    "            curr_state_imgs_paths = self.game_controls.curr_screenshots_paths.copy()\n",
    "            end_game = self.game_controls.end_game\n",
    "#             action_to_be_taken = self.epsilon_greedy_policy_for_action(curr_state_imgs_paths)\n",
    "#             is_training_start = False\n",
    "#             next_state_imgs_paths, curr_reward, end_game, start_training_gap_period = self.perform_a_step_in_an_episode(action_to_be_taken)\n",
    "                \n",
    "\n",
    "#             curr_state_imgs_paths = next_state_imgs_paths.copy()\n",
    "            '''If the current state is not terminal i.e. not end_game'''\n",
    "            while not end_game: \n",
    "                action_to_be_taken = self.epsilon_greedy_policy_for_action(curr_state_imgs_paths)\n",
    "                next_state_imgs_paths, curr_reward, end_game, start_training_gap_period = self.perform_a_step_in_an_episode(action_to_be_taken)\n",
    "                \n",
    "                self.add_experiences_to_buffers_after_running_game_for_one_step(action_to_be_taken, curr_state_imgs_paths.copy(),\n",
    "                                                                                    self.game_controls.curr_screenshots_paths.copy(),\n",
    "                                                                                    curr_reward,\n",
    "                                                                                    end_game)\n",
    "                curr_state_imgs_paths = self.game_controls.curr_screenshots_paths.copy()\n",
    "\n",
    "\n",
    "\n",
    "                '''Train the model on random samples from both the experience buffers'''\n",
    "                self.adjust_buffer_sample_rate(epoch)\n",
    "                buffer_1_samples, buffer_2_samples = self.sample_mini_batches_from_experience_buffers()\n",
    "                buffer_samples = buffer_1_samples + buffer_2_samples\n",
    "                loss = self.train_step(buffer_samples)\n",
    "                loss_log.update_state(loss)\n",
    "#                 print('this episode finished')\n",
    "    \n",
    "                    \n",
    "            \n",
    "            if curr_epoch % 10 == 0 and curr_epoch > 0:\n",
    "                self.save_buffer_experiences_as_npy_files_periodically()\n",
    "                self.checkpoint_manager.save()\n",
    "                print('In epoch ' + str(curr_epoch) + ' the loss is ' + str(loss_log.result()))\n",
    "                loss_log.reset_states()\n",
    "\n",
    "\n",
    "            if curr_epoch == config.NUM_EPOCHS - 1:\n",
    "                self.checkpoint.model.save_weights(config.FINAL_WEIGHTS_DIR + 'snake_game_weights.h5')\n",
    "                self.save_buffer_experiences_as_npy_files_periodically()\n",
    "                self.game_controls.end_the_game()\n",
    "\n",
    "\n",
    "            if curr_epoch != config.NUM_EPOCHS - 1:\n",
    "                self.checkpoint.curr_epoch.assign_add(1)\n",
    "            \n",
    "#             if end_game:\n",
    "#                 self.game_controls.end_the_game_and_start_a_new_one()\n",
    "#                 self.game_controls.new_game = True\n",
    "#                 self.game_controls.set_up_the_screen(False)\n",
    "                    \n",
    "#         except Exception:\n",
    "#             self.game_controls.end_the_game()\n",
    "#             traceback.print_exc()\n",
    "                \n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of steps completed are 1\n",
      "npy files saved and 5000 steps completed\n",
      "npy files saved and 10000 steps completed\n"
     ]
    }
   ],
   "source": [
    "'''If we are starting game (and so observation period) from start then resuming should be False\n",
    "else, True'''\n",
    "\n",
    "train_snake_game = Training()\n",
    "train_snake_game.observation_period()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snake_game.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file = np.load('/Users/vijay/Downloads/Code_Data/snake_game/npy_files/buffer_1_npy.npy', allow_pickle = True)\n",
    "filee = np.load('/Users/vijay/Downloads/Code_Data/snake_game/npy_files/buffer_2_npy.npy', allow_pickle = True)\n",
    "print(len(file), len(filee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in file:\n",
    "\n",
    "    print(p)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('/Users/vijay/Downloads/Code_Data/snake_game/screenshots/')\n",
    "files = [file for file in files if 'DS' not in file]\n",
    "if len(files) != 0:\n",
    "    '''Sort the image names using the integer part'''\n",
    "    files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    recent_img_name = files[-1]\n",
    "    match_object = re.search('\\D', recent_img_name)\n",
    "    num = int(recent_img_name[0:match_object.start()])\n",
    "    print(num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
