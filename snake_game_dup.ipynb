{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev6 (SDL 2.0.10, python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import traceback\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pygame.locals import *\n",
    "# pygame.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Input, Flatten, Dense, Lambda, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "config = edict()\n",
    "\n",
    "config.CHECKPOINT_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/checkpoints/'\n",
    "config.NUM_EPOCHS     = 3\n",
    "config.BATCH_SIZE     = 64\n",
    "config.EPSILON        = 0.9\n",
    "config.BUFFER_SAMPLE_RATE = 0.8\n",
    "config.BUFFER_SAMPLE_RATE_DECAY_RATE = 0.1\n",
    "config.DISCOUNT_FACTOR = 0.99\n",
    "config.IMG_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/screenshots/'\n",
    "config.BUFFERS_NPY_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/npy_files/'\n",
    "config.FINAL_WEIGHTS_DIR = '/Users/vijay/Downloads/Code_Data/snake_game/final_weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settings:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.screen_color = (100, 100, 100)\n",
    "        self.screen_width = 200\n",
    "        self.screen_height = 200\n",
    "        self.run_game = True\n",
    "        self.snake_nodes_group = []\n",
    "        \n",
    "        \n",
    "class Snake_Node:\n",
    "    def __init__(self, node_num, x, y, color, radius):\n",
    "        \n",
    "        self.snake_node_num = node_num\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.radius = radius\n",
    "        self.direction = 'up'\n",
    "        \n",
    "    def draw_snake_node(self, screen):\n",
    "#         snake_node = pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius)\n",
    "        snake_node = pygame.draw.rect(screen, self.color, (self.x, self.y, 10, 10), 1)\n",
    "        return snake_node\n",
    "    \n",
    "    \n",
    "    \n",
    "class Snake_Head:\n",
    "    def __init__(self, x, y, color, radius):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.radius = radius\n",
    "#         self.moving_direction = 'up'\n",
    "    \n",
    "    def draw_snake_head(self, screen):\n",
    "        snake_head = pygame.draw.rect(screen, self.color, (self.x, self.y, 10, 10))\n",
    "#         snake_head = pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius)\n",
    "        return snake_head\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Game_functions:\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_of_steps_in_curr_episode = 0\n",
    "        self.start_training_gap_period = False\n",
    "        self.is_apple_there = False\n",
    "        self.game_settings = settings()\n",
    "        self.divide_screen_into_segments()\n",
    "        self.num_of_snake_nodes = 0\n",
    "        self.snake_head_moving_direction = ' '\n",
    "        self.xy_list = []\n",
    "        self.radius = 10\n",
    "        self.rect_width = 5\n",
    "        self.rect_height = 5\n",
    "        self.full_reward = 0\n",
    "#         self.full_reward = False\n",
    "        self.img_count = 0\n",
    "        self.prev_distance = -1\n",
    "        self.new_game = True\n",
    "        self.score    = 0\n",
    "        self.img_dir  = config.IMG_DIR\n",
    "        \n",
    "        self.create_dirs()\n",
    "        self.set_up_the_screen(True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def create_dirs(self):\n",
    "        if not os.path.exists(self.img_dir):\n",
    "            os.makedirs(self.img_dir)\n",
    "        \n",
    "        if not os.path.exists(config.CHECKPOINT_DIR):\n",
    "            os.makedirs(config.CHECKPOINT_DIR)\n",
    "        \n",
    "        if not os.path.exists(config.BUFFERS_NPY_DIR):\n",
    "            os.makedirs(config.BUFFERS_NPY_DIR)\n",
    "        \n",
    "        if not os.path.exists(config.FINAL_WEIGHTS_DIR):\n",
    "            os.makedirs(config.FINAL_WEIGHTS_DIR)\n",
    "            \n",
    "            \n",
    "    ####################################\n",
    "    \n",
    "    def divide_screen_into_segments(self):\n",
    "        self.segment_indices = []\n",
    "        for i in range(0, 200):\n",
    "            if i % 10 == 0:\n",
    "                self.segment_indices.append(i)\n",
    "                \n",
    "                \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def draw_snake_nodes_xy(self, from_list):\n",
    "        \n",
    "        if from_list:\n",
    "            for index, xy_tuple in enumerate(self.xy_list):\n",
    "                if index != 0:\n",
    "                    self.create_snake_head_or_apple(xy_tuple[0], xy_tuple[1], 5, False)\n",
    "                    pygame.display.update()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def get_new_xy_for_apple(self):\n",
    "        x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "        if (x, y) not in self.xy_list:\n",
    "            return x, y\n",
    "        else:\n",
    "            return self.get_new_xy_for_apple()\n",
    "        \n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def create_snake_head_or_apple(self, x, y, is_apple):\n",
    "        \n",
    "        if not is_apple:\n",
    "            color = (255,255,255)\n",
    "            \n",
    "            if self.num_of_snake_nodes != 0:\n",
    "                \n",
    "                snake_node_obj = Snake_Node(self.num_of_snake_nodes, x, y, color, self.radius)\n",
    "                snake_node = snake_node_obj.draw_snake_node(self.screen)\n",
    "                \n",
    "                \n",
    "            elif self.num_of_snake_nodes == 0:\n",
    "                snake_head_obj = Snake_Head(x, y, (0, 255, 0), self.radius)\n",
    "                self.snake_head = snake_head_obj.draw_snake_head(self.screen)\n",
    "\n",
    "                \n",
    "            self.num_of_snake_nodes = self.num_of_snake_nodes + 1\n",
    "            \n",
    "            if self.num_of_snake_nodes < 5:\n",
    "                pygame.time.wait(80)\n",
    "            else:\n",
    "                pygame.time.wait(10)\n",
    "            \n",
    "        if is_apple:\n",
    "            color = (255, 0, 0)\n",
    "            self.apple = pygame.draw.rect(self.screen, color, (x, y, 10, 10))\n",
    "#             self.apple = pygame.draw.circle(self.screen, color, (x, y), self.radius)\n",
    "            self.is_apple_there = True\n",
    "            self.apple_x = x\n",
    "            self.apple_y = y\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def start_a_new_game(self):\n",
    "#         print('start a new game')\n",
    "        if self.new_game:\n",
    "#             self.set_up_the_screen()\n",
    "            self.is_apple_there     = False\n",
    "            self.num_of_snake_nodes = 0\n",
    "            self.xy_list.clear()\n",
    "            self.screen.fill((100, 100, 100))\n",
    "            self.prev_distance      = -1\n",
    "#             self.img_count          = 0\n",
    "#             self.full_reward        = 0\n",
    "            self.score              = 0\n",
    "            \n",
    "            x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "            self.xy_list.append((x, y))\n",
    "            self.draw_rect_at_new_location()\n",
    "            self.new_game           = False\n",
    "#             self.set_up_the_screen()\n",
    "\n",
    "    ####################################\n",
    "    \n",
    "    def check_if_snake_is_at_boundaries(self, new_x, new_y, direction):\n",
    "\n",
    "        if direction == 'up':\n",
    "            if new_y  < 0:\n",
    "                return True\n",
    "    \n",
    "\n",
    "        if direction == 'down':\n",
    "            if new_y  >= self.game_settings.screen_width:\n",
    "                return True\n",
    "    \n",
    "\n",
    "        if direction == 'left':\n",
    "            if new_x  < 0:\n",
    "                return True\n",
    "  \n",
    "\n",
    "        if direction == 'right':\n",
    "            if new_x  >= self.game_settings.screen_width:\n",
    "                return True\n",
    "        \n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####################################\n",
    "\n",
    "    def draw_rect_at_new_location(self):\n",
    "        \n",
    "        self.screen.fill((100, 100, 100))\n",
    "        self.num_of_snake_nodes = 0\n",
    "        \n",
    "        for xy_tuple in self.xy_list:        \n",
    "            self.create_snake_head_or_apple(xy_tuple[0], xy_tuple[1], False)\n",
    "    \n",
    "        \n",
    "        self.create_apple()\n",
    "        pygame.display.update()\n",
    "\n",
    "\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def get_new_x_y_for_moving(self, x, y, direction):\n",
    "        \n",
    "        if direction == 'up':\n",
    "            y = y - self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'down':\n",
    "            y = y + self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'left':\n",
    "            x = x - self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'right':\n",
    "            x = x + self.radius\n",
    "        \n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "#     ###################################\n",
    "    \n",
    "    def move_nodes(self, head_direction):\n",
    "        prev_tuple = (-1, -1)\n",
    "        curr_tuple = (-1, -1)\n",
    "        for index, xy_tuple in enumerate(self.xy_list):\n",
    "            if index == 0:\n",
    "                prev_tuple = xy_tuple\n",
    "            elif index != 0:\n",
    "                curr_tuple = self.xy_list[index]\n",
    "                self.xy_list[index] = prev_tuple\n",
    "                prev_tuple = curr_tuple\n",
    "        \n",
    "    \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def check_if_snake_ran_into_its_own_body(self):\n",
    "        \n",
    "        tuple_counter = Counter(self.xy_list)\n",
    "        if tuple_counter[self.xy_list[0]] != 1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    " \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def move_snake_head_new(self, direction):\n",
    "        \n",
    "        '''\n",
    "        First, get the new xy for the snake head to move\n",
    "        check whether the snake head is at the boundaries wrt new xy\n",
    "        if not, get new xy for all the snake nodes \n",
    "        update the xy_list with all the new xy values of both nodes and head\n",
    "        after updating, check, after moving, if the head bumped into its own body\n",
    "        '''\n",
    "#         end_game_in_curr_step = False\n",
    "        \n",
    "        x, y = self.xy_list[0][0], self.xy_list[0][1]\n",
    "        new_x, new_y = self.get_new_x_y_for_moving(x, y, direction)\n",
    "#         if new_x == -1 and new_y == -1:\n",
    "#             is_snake_at_boundary = True\n",
    "#         else:\n",
    "#             is_snake_at_boundary = False\n",
    "#         print(new_x, new_y)\n",
    "        is_snake_at_boundary = self.check_if_snake_is_at_boundaries(new_x, new_y, direction)\n",
    "\n",
    "        if not is_snake_at_boundary:\n",
    "#             print('not bound')\n",
    "            self.move_nodes(direction)\n",
    "            self.xy_list[0] = (new_x, new_y)\n",
    "            snake_ran_into_its_own_body = self.check_if_snake_ran_into_its_own_body()\n",
    "            if not snake_ran_into_its_own_body:\n",
    "                self.new_game = False\n",
    "#                 self.move_nodes(direction)\n",
    "                self.draw_rect_at_new_location()\n",
    "#                 pygame.display.update()\n",
    "#                 print(new_x_, new_y)\n",
    "            else:\n",
    "                '''\n",
    "                if the snake bumped into its own body, then a reward of -1 has to be given to the snake\n",
    "                '''\n",
    "                \n",
    "                self.full_reward = -1\n",
    "                self.new_game    = True\n",
    "#                 end_game_in_curr_step = True\n",
    "#                 self.end_game()\n",
    "#                 self.start_a_new_game()\n",
    "            \n",
    "\n",
    "        else:\n",
    "            '''\n",
    "            if the snake bumped into any boundary, then a reward of -1 has to be given to the snake\n",
    "            '''\n",
    "#             print('bundar')\n",
    "#             print(new_x, new_y)\n",
    "            self.full_reward = -1\n",
    "            self.new_game  = True\n",
    "#             end_game_in_curr_step = True\n",
    "#             self.end_game()\n",
    "#             self.start_a_new_game()\n",
    "\n",
    "        \n",
    "#         return end_game_in_curr_step\n",
    "        \n",
    "    \n",
    "\n",
    "    ####################################\n",
    "    \n",
    "    def create_apple(self):\n",
    "        \n",
    "        if not self.is_apple_there:\n",
    "            x, y = self.get_new_xy_for_apple()\n",
    "#             x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "            \n",
    "            self.create_snake_head_or_apple(x, y, True)\n",
    "        \n",
    "        if self.is_apple_there:\n",
    "            self.create_snake_head_or_apple(self.apple_x, self.apple_y, True)\n",
    "            \n",
    "        pygame.display.update()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    '''\n",
    "    if an action is supplied (direction) and in that direction, if there is a node in that direction, then stop moving it\n",
    "    \n",
    "    '''\n",
    "    def check_whether_to_move_nodes_or_not(self, direction):\n",
    "        if direction == 'up':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] and self.xy_list[0][1] == self.xy_list[1][1] + self.radius:\n",
    "                return False\n",
    "        \n",
    "        elif direction == 'down':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] and self.xy_list[0][1] == self.xy_list[1][1] - self.radius:\n",
    "                return False\n",
    "        \n",
    "        elif direction == 'left':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] + self.radius and self.xy_list[0][1] == self.xy_list[1][1]:\n",
    "                return False\n",
    "            \n",
    "        elif direction == 'right':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] - self.radius and self.xy_list[0][1] == self.xy_list[1][1]:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    def get_new_xy_for_new_node_after_eating_apple(self):\n",
    "        \n",
    "        last_node_x, last_node_y = self.xy_list[-1][0], self.xy_list[-1][1]\n",
    "        new_x, new_y = -1, -1\n",
    "        \n",
    "        if last_node_x + self.radius < self.game_settings.screen_width:\n",
    "            if (last_node_x + self.radius, last_node_y) not in self.xy_list: \n",
    "                new_x = last_node_x + self.radius\n",
    "                new_y = last_node_y\n",
    "        \n",
    "        elif last_node_x - self.radius > 0:\n",
    "            if (last_node_x - self.radius, last_node_y) not in self.xy_list:\n",
    "                new_x = last_node_x - self.radius\n",
    "                new_y = last_node_y\n",
    "        \n",
    "        \n",
    "        elif last_node_y - self.radius > 0 :\n",
    "            if (last_node_x, last_node_y - self.radius) not in self.xy_list: \n",
    "                new_x = last_node_x\n",
    "                new_y = last_node_y -self.radius5\n",
    "            \n",
    "        elif last_node_y + self.radius < self.game_settings.screen_width:\n",
    "            if (last_node_x, last_node_y + self.radius) not in self.xy_list:\n",
    "                new_x = last_node_x\n",
    "                new_y = last_node_y + self.radius\n",
    "            \n",
    "        \n",
    "        return new_x, new_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    def add_just_eaten_apple_to_the_snake_end(self):\n",
    "        \n",
    "        new_node_x, new_node_y = self.get_new_xy_for_new_node_after_eating_apple()\n",
    "        self.xy_list.append((new_node_x, new_node_y))\n",
    "        self.is_apple_there = False\n",
    "        self.draw_rect_at_new_location()\n",
    "        self.start_training_gap_period = True\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    '''\n",
    "    if apple's xy and snake_head's xy (first value in xy_list), then we consider that snake has eaten apple\n",
    "    '''\n",
    "    def is_apple_eaten(self):\n",
    "        \n",
    "        if self.is_apple_there:\n",
    "            if self.apple_x == self.xy_list[0][0] and self.apple_y == self.xy_list[0][1]:\n",
    "                '''\n",
    "                if apple is eaten, a full reward of 1 has to be given to the snake\n",
    "                '''\n",
    "                self.full_reward = 1\n",
    "                self.score = self.score + 10\n",
    "                self.add_just_eaten_apple_to_the_snake_end()\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def check_if_snake_moved_closer_to_apple(self):\n",
    "        \n",
    "        snake_head_xy = self.xy_list[0]\n",
    "        apple_xy      = (self.apple_x, self.apple_y)\n",
    "        \n",
    "        curr_distance = math.sqrt( ((snake_head_xy[0] - apple_xy[0]) ** 2) + ((snake_head_xy[1] - apple_xy[1]) ** 2))\n",
    "        \n",
    "        if self.prev_distance == -1:\n",
    "            self.prev_distance = curr_distance\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            if curr_distance < self.prev_distance:\n",
    "                return True\n",
    "            else: \n",
    "                False\n",
    "            self.prev_distance = curr_distance\n",
    "        \n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def get_reward(self):\n",
    "        '''\n",
    "        -- if snake_head moved towards apple, reward = 0.2\n",
    "        --                            if not, reward = -0.2\n",
    "        --- if snake bumped into its own body or bumped into boundaries, reward = -1\n",
    "        --- if snake eats apple, reward = 1\n",
    "        --- if snake cannot move, then reward = -0.1\n",
    "        '''\n",
    "        if self.full_reward == 0:\n",
    "            moved_closer = self.check_if_snake_moved_closer_to_apple()\n",
    "            if moved_closer:\n",
    "                return 0.2\n",
    "            \n",
    "            elif not moved_closer:\n",
    "                return -0.2\n",
    "        \n",
    "        else:\n",
    "            return self.full_reward\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    def get_curr_state_of_the_game(self):\n",
    "        \n",
    "        '''\n",
    "        -- Stacking last 4 screenshots of the image as one\n",
    "        -- if the num of screenshots is less than 4, then the last screenshot has to be appended \n",
    "            required num of times\n",
    "        --- if the num of screenshots is greater than 4, then the recent last 4 screenshots have to be \n",
    "            appended\n",
    "        '''\n",
    "#         print('  previous')\n",
    "#         for path in self.curr_screenshots_paths:\n",
    "#             print(path)\n",
    "        \n",
    "#         print(' ')\n",
    "        self.curr_screenshots_paths.clear()\n",
    "        img_ids = []\n",
    "        if self.img_count < 4 and self.img_count > 0:\n",
    "            for id_ in range(self.img_count):\n",
    "                img_ids.append(id_)\n",
    "            remaining = 4 - self.img_count\n",
    "            for _ in range(remaining):\n",
    "                img_ids.append(img_ids[-1])\n",
    "\n",
    "        elif self.img_count >= 4:\n",
    "            for id_ in range(1, 5):\n",
    "                img_ids.append(self.img_count - id_)\n",
    "        \n",
    "            img_ids.reverse()\n",
    "        \n",
    "        for id_ in img_ids:\n",
    "            self.curr_screenshots_paths.append(self.img_dir + str(id_) + '.jpg')\n",
    "        reward = self.get_reward()        \n",
    "        end_game = self.new_game\n",
    "        \n",
    "#         self.curr_screenshot_path = curr_screenshot_path\n",
    "        self.curr_reward = reward\n",
    "        self.end_game    = end_game\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    ###################################    \n",
    "    '''\n",
    "    -- if we started the game newly then is_game_just_started is set to True.\n",
    "    -- if game ended because of the snake bumping into itself or into boundaries, then we have to end the current game and have to \n",
    "        start a new game. In this case, is_game_just_started is set to False\n",
    "    '''\n",
    "    def set_up_the_screen(self, is_game_just_started):\n",
    "        pygame.init()\n",
    "        pygame.display.init()\n",
    "        self.screen = pygame.display.set_mode((self.game_settings.screen_width, self.game_settings.screen_height))\n",
    "        pygame.display.flip()\n",
    "        self.start_a_new_game()\n",
    "        \n",
    "        if is_game_just_started:\n",
    "#             pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "            self.img_count = self.img_count + 1\n",
    "            self.curr_screenshots_paths = []\n",
    "            self.curr_reward = 0\n",
    "            self.end_game = False\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def end_the_game_and_start_a_new_one(self):\n",
    "    \n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "        exit()\n",
    "        self.new_game = True\n",
    "        self.set_up_the_screen(False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def end_the_game(self):\n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "        exit()\n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def run(self, action):\n",
    "#         while self.game_settings.run_game:\n",
    "        try:\n",
    "            \n",
    "            apple_eaten = False\n",
    "            events = pygame.event.get()\n",
    "            \n",
    "            for event in events:\n",
    "                if event.type == pygame.KEYDOWN:\n",
    "                    if event.key == pygame.K_x:\n",
    "                        self.game_settings.run_game = False\n",
    "                        pygame.display.quit()\n",
    "                        pygame.quit()\n",
    "                        exit()\n",
    "                    \n",
    "                \n",
    "            if self.num_of_snake_nodes == 1:\n",
    "                move_nodes = True\n",
    "\n",
    "            keys = pygame.key.get_pressed()\n",
    "            \n",
    "            if keys[pygame.K_x]:\n",
    "                self.game_settings.run_game = False\n",
    "                pygame.display.quit()\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "            ############\n",
    "\n",
    "            if action == 'up':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "\n",
    "\n",
    "            ##############\n",
    "\n",
    "            elif action == 'down':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "\n",
    "\n",
    "            ##############\n",
    "\n",
    "            elif action == 'left':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ###########\n",
    "\n",
    "            elif action == 'right':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "#                     self.img_count = self.img_count + 1\n",
    "    \n",
    "            if not self.new_game:\n",
    "                self.is_apple_eaten()\n",
    "                pygame.display.flip()\n",
    "#             if not self.end_game:\n",
    "                pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "                self.img_count = self.img_count + 1\n",
    "            self.get_curr_state_of_the_game()\n",
    "#             else:\n",
    "#                 self.end_the_game()\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# game_functions = Game_functions()\n",
    "# # game_functions.run('test')\n",
    "# for i in range(200):\n",
    "#     actions = ['right', 'right', 'right', 'left']\n",
    "#     action_index = random.randint(0, 3)\n",
    "#     action = actions[action_index]\n",
    "#     game_functions.run(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Q_values_approximator_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def normalize_to_range_01(self, img):\n",
    "        return tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    def get_q_values(self):\n",
    "        input_data = Input(shape = (64, 64, 12))\n",
    "        data = Lambda(self.normalize_to_range_01)(input_data)\n",
    "        data = Conv2D(filters = 32, kernel_size = 7, strides = (4, 4), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Conv2D(filters = 64, kernel_size = 5, strides = (2, 2), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Conv2D(filters = 128, kernel_size = 3, strides = (2, 2), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Flatten()(data)\n",
    "        data = Dense(512)(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Dense(4)(data)\n",
    "        \n",
    "        self.model = tf.keras.Model(input_data, data)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.game_controls = Game_functions()\n",
    "        self.training_gap_steps = 0\n",
    "        self.experiences_buffer_1   = []\n",
    "        self.experiences_buffer_2 = []\n",
    "        self.observation_period_threshold = 600\n",
    "        self.num_of_steps_completed_in_obv_period = 0\n",
    "        self.actions = ['up', 'down', 'right', 'left']\n",
    "        \n",
    "        q_values_predictor = Q_values_approximator_model()\n",
    "        q_values_predictor.get_q_values()\n",
    "        self.q_values_pred_model = q_values_predictor.model\n",
    "        self.model_optimizer = Adam(learning_rate = 0.001)\n",
    "        self.checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "                                              optimizer = self.model_optimizer,\n",
    "                                              model = self.q_values_pred_model \n",
    "                                             )\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, \n",
    "                                                            directory = config.CHECKPOINT_DIR,\n",
    "                                                            max_to_keep = 3)\n",
    "        self.mse_loss = MeanAbsoluteError()\n",
    "        self.buffers_max_len = 550\n",
    "        self.from_index_to_add_exp_buffer_1 = -1\n",
    "        self.from_index_to_add_exp_buffer_2 = -1\n",
    "        \n",
    "    ############################################\n",
    "        \n",
    "    def preprocess_and_stack_images(self, curr_game_images_paths):\n",
    "#         print(' ')\n",
    "#         print(curr_game_images_paths)\n",
    "#         print(' ')\n",
    "        images = []\n",
    "        for image_path in curr_game_images_paths:\n",
    "#             print(image_path)\n",
    "            image = cv2.resize(cv2.imread(image_path), (64, 64))\n",
    "            images.append(image)\n",
    "        \n",
    "        stacked_images = np.concatenate((images[0], images[1], images[2], images[3]), axis = 2)\n",
    "        return stacked_images\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    '''\n",
    "    After deciding upon action to be taken, run the game for one step\n",
    "    Then, collect the next state images paths, reward received and whether the next state is terminal\n",
    "    '''\n",
    "    def perform_a_step_in_an_episode(self, action):\n",
    "        \n",
    "        self.game_controls.run(action)\n",
    "        game_imgs_paths_after_action = self.game_controls.curr_screenshots_paths \n",
    "        reward_after_action = self.game_controls.curr_reward\n",
    "        end_game_after_action = self.game_controls.end_game\n",
    "        start_training_gap_period = self.game_controls.start_training_gap_period\n",
    "\n",
    "        return game_imgs_paths_after_action, reward_after_action, end_game_after_action, start_training_gap_period\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def determing_num_of_training_gap_steps_after_snake_eating_apple(self):\n",
    "        length_of_snake = self.game_controls.score \n",
    "        k = 10\n",
    "        p = 0.4\n",
    "        q = 0.2\n",
    "        if length_of_snake <= k:\n",
    "            self.training_gap_steps = 6\n",
    "        elif length_of_snake > k:\n",
    "            self.training_gap_steps = math.ceil((p * length_of_snake) + q)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def check_if_buffers_reached_their_maximum_capacity(self, buffer_num):\n",
    "        \n",
    "        if buffer_num == 1: #and len(self.experiences_buffer_1) == self.buffers_max_len:\n",
    "            if self.from_index_to_add_exp_buffer_1 == -1 or self.from_index_to_add_exp_buffer_1 >= self.buffers_max_len:\n",
    "                self.from_index_to_add_exp_buffer_1 = 0\n",
    "\n",
    "        \n",
    "        elif buffer_num == 2: #and len(self.experiences_buffer_2) == self.buffers_max_len:\n",
    "            if self.from_index_to_add_exp_buffer_2 == -1 or self.from_index_to_add_exp_buffer_2 >= self.buffers_max_len:\n",
    "                self.from_index_to_add_exp_buffer_2 = 0\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def save_buffer_experiences_as_npy_files_periodically(self):\n",
    "        npy_files = glob.glob(config.BUFFERS_NPY_DIR + '*')\n",
    "        for file in npy_files:\n",
    "            os.remove(file)\n",
    "#         print(len(self.experiences_buffer_1), len(self.experiences_buffer_2))\n",
    "        np.save(config.BUFFERS_NPY_DIR + 'buffer_1_npy.npy', self.experiences_buffer_1)\n",
    "        np.save(config.BUFFERS_NPY_DIR + 'buffer_2_npy.npy', self.experiences_buffer_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    '''\n",
    "    --- Get an action and run the game as per the action\n",
    "    --- Now, record the updated state of the game by getting the curr screenshot of the screen, \n",
    "         current reward and also whether the current state resulted in quitting game which happens\n",
    "         when snake bumps into boundaries or ran into itself.\n",
    "\n",
    "    '''\n",
    "    def add_experiences_to_buffers_after_running_game_for_one_step(self, action, curr_state_imgs_paths, \n",
    "                                                                               next_state_imgs_paths, reward_after_action, end_game):\n",
    "        \n",
    "        self.check_if_buffers_reached_their_maximum_capacity(1)\n",
    "        self.check_if_buffers_reached_their_maximum_capacity(2)\n",
    "#         print(self.from_index_to_add_exp_buffer_1, self.from_index_to_add_exp_buffer_2)\n",
    "        buffer_1_len = len(self.experiences_buffer_1)\n",
    "        buffer_2_len = len(self.experiences_buffer_2)\n",
    "        print(self.from_index_to_add_exp_buffer_1, self.from_index_to_add_exp_buffer_2)\n",
    "        if reward_after_action < 0:\n",
    "            \n",
    "            if buffer_1_len == self.buffers_max_len - 1:\n",
    "                self.experiences_buffer_1[self.from_index_to_add_exp_buffer_1] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "            elif buffer_1_len < self.buffers_max_len - 1:\n",
    "                self.experiences_buffer_1.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "            \n",
    "            self.from_index_to_add_exp_buffer_1 = self.from_index_to_add_exp_buffer_1 + 1\n",
    "            \n",
    "#             if self.from_index_to_add_exp_buffer_1 == -1:\n",
    "#                 self.experiences_buffer_1.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "#             else:\n",
    "#                 self.experiences_buffer_1[self.from_index_to_add_exp_buffer_1] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "#                 self.from_index_to_add_exp_buffer_1 = self.from_index_to_add_exp_buffer_1 + 1\n",
    "        \n",
    "        else:\n",
    "            if buffer_2_len == self.buffers_max_len - 1:\n",
    "                self.experiences_buffer_2[self.from_index_to_add_exp_buffer_2] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "            elif buffer_2_len < self.buffers_max_len - 1:\n",
    "                self.experiences_buffer_2.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "            \n",
    "            self.from_index_to_add_exp_buffer_2 = self.from_index_to_add_exp_buffer_2 + 1\n",
    "            \n",
    "            \n",
    "            \n",
    "#             if self.from_index_to_add_exp_buffer_2 == -1:\n",
    "#                 self.experiences_buffer_2.append([curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game])\n",
    "#             else:\n",
    "#                 self.experiences_buffer_2[self.from_index_to_add_exp_buffer_2] = [curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game]\n",
    "#                 self.from_index_to_add_exp_buffer_2 = self.from_index_to_add_exp_buffer_2 + 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def start_exploration_in_observation_period(self, resuming):\n",
    "        \n",
    "        '''If not resuming (if we are staring now), that means, we have just started and there is no current state\n",
    "        Therefore, for two steps, choose a random action and then carry on forward'''\n",
    "        if not resuming: \n",
    "            steps_taken = 0\n",
    "            while steps_taken < 5:\n",
    "                \n",
    "                action = self.actions[random.randint(0, 3)]\n",
    "                self.perform_a_step_in_an_episode(action)\n",
    "                \n",
    "                steps_taken = steps_taken + 1\n",
    "            \n",
    "\n",
    "              \n",
    "        num_of_training_gap_steps_completed = 0\n",
    "        enter_training_gap_period = False\n",
    "        if resuming:\n",
    "            self.game_controls.get_curr_state_of_the_game()\n",
    "        curr_state_imgs_paths = self.game_controls.curr_screenshots_paths.copy()\n",
    "        curr_reward           = self.game_controls.curr_reward\n",
    "        end_game              = self.game_controls.end_game\n",
    "        start_training_gap    = self.game_controls.start_training_gap_period\n",
    "#         curr_state           = self.preprocess_and_stack_images(curr_game_imgs_paths)\n",
    "\n",
    "        while self.num_of_steps_completed_in_obv_period < self.observation_period_threshold and not end_game:\n",
    "        \n",
    "            \n",
    "            '''\n",
    "            -- so, when the snake eats an apple, then we should immediately enter into a training_gap_period during which no experiences are\n",
    "                stored into experience buffers.\n",
    "            \n",
    "            -- if start_training_gap and enter_training_gap_period == False, then we haven't entered the training_gap and therefore set\n",
    "                enter_training_gap_period = True\n",
    "            \n",
    "            -- if not start_training_gap, then add experiences to the buffer. if in training_gap_period, then just perform single step in the game\n",
    "                without storing experiences in the experience buffers. Also, increase the number of steps completed in trainig_gap_period\n",
    "            \n",
    "            -- if the num_of_steps in training_gap is equal to the pre-determined num_of_steps in training_gap_period, then exit training_gap_period\n",
    "                by setting enter_training_gap_period = False and self.game_controls.start_training_gap_period = False\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            if self.num_of_steps_completed_in_obv_period % 599 == 0 and self.num_of_steps_completed_in_obv_period > 0:\n",
    "                self.save_buffer_experiences_as_npy_files_periodically()\n",
    "                print('npy files saved and ' + str(self.num_of_steps_completed_in_obv_period) + ' steps completed')\n",
    "\n",
    "                \n",
    "                \n",
    "            if start_training_gap and not enter_training_gap_period:\n",
    "                enter_training_gap_period = True\n",
    "                self.determing_num_of_training_gap_steps_after_snake_eating_apple()\n",
    "            \n",
    "            \n",
    "            if enter_training_gap_period and (num_of_training_gap_steps_completed == self.training_gap_steps - 1):\n",
    "                enter_training_gap_period = False\n",
    "                self.game_controls.start_training_gap_period = False\n",
    "            \n",
    "            action = self.actions[random.randint(0, 3)]\n",
    "            \n",
    "            next_state_imgs_paths, reward_after_action, end_game, start_training_gap = self.perform_a_step_in_an_episode(action)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if not enter_training_gap_period:\n",
    "\n",
    "                \n",
    "                self.add_experiences_to_buffers_after_running_game_for_one_step(action, curr_state_imgs_paths.copy(), \n",
    "                                                                               self.game_controls.curr_screenshots_paths.copy(), \n",
    "                                                                                self.game_controls.curr_reward, self.game_controls.end_game)  \n",
    "            elif enter_training_gap_period:\n",
    "                num_of_training_gap_steps_completed = num_of_training_gap_steps_completed + 1\n",
    "\n",
    "            curr_state_imgs_paths = next_state_imgs_paths.copy()\n",
    "            self.num_of_steps_completed_in_obv_period = self.num_of_steps_completed_in_obv_period + 1\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "        \n",
    "    def restore_checkpoint(self):\n",
    "\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print('restored checkpoint successfully at epoch ' + str(self.checkpoint.curr_epoch.numpy()))\n",
    "        else:\n",
    "            print('No checkpoint restoration')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    def epsilon_greedy_policy_for_action(self, curr_state_imgs_paths):\n",
    "        if random.random() < config.EPSILON:\n",
    "            return self.actions[random.randint(0, 3)]\n",
    "        else:\n",
    "            curr_state_imgs = self.preprocess_and_stack_images(curr_state_imgs_paths)\n",
    "            q_values = self.checkpoint.model(np.expand_dims(curr_state_imgs, axis = 0), training = True)\n",
    "            return self.actions[np.argmax(q_values.numpy()[0])]\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    def adjust_buffer_sample_rate(self, epoch):\n",
    "        if epoch % 1000 == 0:\n",
    "            decay_value = config.BUFFER_SAMPLE_RATE * config.BUFFER_SAMPLE_RATE_DECAY_RATE\n",
    "            new_buffer_sample_rate = config.BUFFER_SAMPLE_RATE - decay_value\n",
    "            if not new_buffer_sample_rate > 0.5:\n",
    "                config.BUFFER_SAMPLE_RATE = new_buffer_sample_rate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def sample_mini_batches_from_experience_buffers(self):\n",
    "        \n",
    "        experience_1_buffer_length = len(self.experiences_buffer_1)\n",
    "        experience_2_buffer_length = len(self.experiences_buffer_2)\n",
    "        required_num_of_samples_from_buffer_1 = int(64 * config.BUFFER_SAMPLE_RATE)\n",
    "        \n",
    "        if experience_1_buffer_length < required_num_of_samples_from_buffer_1:\n",
    "            num_samples_from_buffer_1 = experience_1_buffer_length\n",
    "        else:\n",
    "            num_samples_from_buffer_1 = int(64 * config.BUFFER_SAMPLE_RATE)\n",
    "            \n",
    "        num_samples_from_buffer_2 = 64 - num_samples_from_buffer_1\n",
    "\n",
    "        random_samples_from_buffer_1 = random.sample(self.experiences_buffer_1, num_samples_from_buffer_1)\n",
    "        random_samples_from_buffer_2 = random.sample(self.experiences_buffer_2, num_samples_from_buffer_2)\n",
    "\n",
    "        return random_samples_from_buffer_1, random_samples_from_buffer_2\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    def get_target_labels_for_samples(self, buffer_samples):\n",
    "        '''\n",
    "        experience[0] = curr_State_imgs_paths\n",
    "        experience[1] = action [This is a text 'up', 'down', 'left', 'right']\n",
    "        experience[2] = reward_after_action\n",
    "        experience[3] = next_state_imgs_paths\n",
    "        experience[4] = end_game\n",
    "        '''\n",
    "\n",
    "        \n",
    "        temp_labels = []\n",
    "        for experience in buffer_samples:\n",
    "            if experience[4]:\n",
    "                temp_labels.append([True, experience[0], experience[2]])\n",
    "            \n",
    "            else:\n",
    "                temp_labels.append([False, experience[3], experience[2]])\n",
    "        \n",
    "        return temp_labels\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    '''\n",
    "    -- In total we would get a total of 64 experiences sampled from buffer experiences.\n",
    "    -- Now, for actual labels, we have run through all the screenshots of the game through the model.\n",
    "    -- In other words, either we should run the model for each screenshots in all the 64 experiences separately, or\n",
    "    -- we can group together all the images in all the experiences as one and the we can run the model on this single set of all images.\n",
    "    -- In the later case, the shape of the input to the model would be, [64, 64, 64, 12]\n",
    "    -- 64 - total num of experiences (each experience will have one of the screenshots)\n",
    "        64 , 64 - would be the size of the each image\n",
    "        12 - here, each screenshot will have 3 channels and we consider recent 4 screenshots. If we concatenate all the 4 screenshots, \n",
    "        then the number of channels will be 12\n",
    "    '''\n",
    "    def get_actual_labels_for_samples(self, buffer_samples):\n",
    "        actual_labels = []\n",
    "        images = []\n",
    "        action_values = []\n",
    "        for experience in buffer_samples:\n",
    "            curr_state_imgs_paths = experience[0]\n",
    "            action = experience[1]\n",
    "            action_index = self.actions.index(action)\n",
    "            action_values.append(action_index)\n",
    "            curr_state_imgs = self.preprocess_and_stack_images(curr_state_imgs_paths)\n",
    "            images.append(curr_state_imgs)\n",
    "          \n",
    "        return images, action_values\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def loss_function(self, target_labels, actual_labels):\n",
    "        return np.square(np.asarray(target_labels) - np.asarray(actual_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def train_step(self, buffer_samples):\n",
    "        \n",
    "            \n",
    "        with tf.GradientTape(persistent = True) as params_tape:\n",
    "            target_label_values_img_paths = self.get_target_labels_for_samples(buffer_samples)\n",
    "            images, action_values = self.get_actual_labels_for_samples(buffer_samples)\n",
    "            \n",
    "            target_label_values_for_samples = []\n",
    "            actual_label_values_for_samples = []\n",
    "            '''\n",
    "            entry is list of three values:\n",
    "            either\n",
    "                1. bool value telling second value is a label value (in this case, True)\n",
    "                2. a label value (reward_after_action)\n",
    "                3. -1\n",
    "            \n",
    "            or\n",
    "                1. bool value telling we have to calculate the label value using next_state_img_paths (in this case, False)\n",
    "                2. next_state_img_paths\n",
    "                3. reward_after_action\n",
    "            '''\n",
    "            # calculation target_values\n",
    "            for entry in target_label_values_img_paths:\n",
    "                if entry[0]: # if game_ended at this step then label = reward\n",
    "                    target_label_values_for_samples.append(entry[2])\n",
    "                \n",
    "                else: # else label = reward + gamma * max(model(images, action))\n",
    "                    next_state_imgs = self.preprocess_and_stack_images(entry[1])\n",
    "                    q_values_of_actions = self.checkpoint.model(np.expand_dims(next_state_imgs, axis = 0), training = True)\n",
    "                    \n",
    "#                     target_value = entry[2] + (config.DISCOUNT_FACTOR * np.max(q_values_of_actions.numpy()[0]))\n",
    "                    target_value = entry[2] + (config.DISCOUNT_FACTOR * tf.math.reduce_max(q_values_of_actions))\n",
    "                    target_label_values_for_samples.append(target_value)\n",
    "            \n",
    "            \n",
    "            # calculating actual labels\n",
    "            q_values_of_actions_a = self.checkpoint.model(np.asarray(images), training = True)\n",
    "#             q_values_of_actions_numpy = q_values_of_actions_a\n",
    "        \n",
    "            for index, q_values in enumerate(q_values_of_actions_a):\n",
    "#             for index, q_values in enumerate(q_values_of_actions_numpy):\n",
    "                actual_label_values_for_samples.append(q_values[action_values[index]])\n",
    "\n",
    "#             if self.count == 0:\n",
    "#                 print(type(target_label_values_for_samples))\n",
    "#                 print(target_label_values_for_samples)\n",
    "#                 print('---------------')\n",
    "#                 print(type(actual_label_values_for_samples))\n",
    "#                 print(actual_label_values_for_samples)\n",
    "                                                       \n",
    "            loss = self.mse_loss(tf.convert_to_tensor(actual_label_values_for_samples), \n",
    "                                 tf.convert_to_tensor(target_label_values_for_samples))\n",
    "            \n",
    "        model_gradients = params_tape.gradient(tf.cast(loss, tf.float32), self.checkpoint.model.trainable_variables)\n",
    "        \n",
    "        self.checkpoint.optimizer.apply_gradients(zip(model_gradients, self.checkpoint.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "                \n",
    "        \n",
    "    \n",
    "\n",
    "    ############################################\n",
    "    \n",
    "    '''\n",
    "    Now, when we resume game after a pause or a stop, then we have to know how many number of steps completed in the \n",
    "    observation period so that we can resume recording experiences from that step onwards. To achieve this, before starting\n",
    "    recording experiences in observation period, we should how many number of experiences are there in each buffer which\n",
    "    we can know by reading the npy files of the buffers stored in config.BUFFERS_NPY_DIR directory. If we add the number\n",
    "    of experiences in both the npy files, then we can know how many total number of steps are completed in observation \n",
    "    period, as each experience is recorded after completing one individual game step.\n",
    "    '''\n",
    "    \n",
    "    def check_the_num_of_steps_completed_in_observation_period(self):\n",
    "        num_of_steps_completed_in_obsv_period = 0\n",
    "        files = glob.glob(config.BUFFERS_NPY_DIR + '*')\n",
    "        if len(files) != 0:\n",
    "            for file in files:\n",
    "                \n",
    "                buffer_experiences = np.load(file, allow_pickle = True)\n",
    "                if 'buffer_1_npy' in file:\n",
    "                    self.experiences_buffer_1 = list(buffer_experiences)\n",
    "                    self.from_index_to_add_exp_buffer_1 = len(self.experiences_buffer_1)\n",
    "                \n",
    "                else:\n",
    "                    self.experiences_buffer_2 = list(buffer_experiences)\n",
    "                    self.from_index_to_add_exp_buffer_2 = len(self.experiences_buffer_2)\n",
    "                num_of_steps_completed_in_obsv_period = num_of_steps_completed_in_obsv_period + len(buffer_experiences)\n",
    "                \n",
    "            \n",
    "            \n",
    "            return num_of_steps_completed_in_obsv_period \n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def check_for_in_screenshots_and_get_images_count(self):\n",
    "        files = os.listdir(self.game_controls.img_dir)\n",
    "        files = [file for file in files if 'DS' not in file]\n",
    "        if len(files) != 0:\n",
    "            '''Sort the image names using the integer part'''\n",
    "            files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "            recent_img_name = files[-1]\n",
    "            match_object = re.search('\\D', recent_img_name)\n",
    "            num = int(recent_img_name[0:match_object.start()])\n",
    "            return num\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    def observation_period(self, resuming):\n",
    "        '''\n",
    "        For the first 50000 seteps, just let the agent choose random actions and explore very\n",
    "        extensively so tha it could have a vast experience buffer\n",
    "        '''\n",
    "#         try:\n",
    "        self.game_controls.img_count = self.check_for_in_screenshots_and_get_images_count()\n",
    "        obsv_period_steps_completed = self.check_the_num_of_steps_completed_in_observation_period()\n",
    "        \n",
    "        if self.game_controls.img_count > 45000:\n",
    "            self.num_of_steps_completed_in_obv_period = self.observation_period_threshold - 1\n",
    "            \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            if self.game_controls.img_count > obsv_period_steps_completed:\n",
    "                self.num_of_steps_completed_in_obv_period = self.game_controls.img_count\n",
    "            else:\n",
    "                self.num_of_steps_completed_in_obv_period = obsv_period_steps_completed\n",
    "\n",
    "            print('num of steps completed are ' + str(self.num_of_steps_completed_in_obv_period))\n",
    "            if not self.num_of_steps_completed_in_obv_period == self.observation_period_threshold - 1:\n",
    "                self.start_exploration_in_observation_period(resuming)\n",
    "                resuming = True\n",
    "                while self.num_of_steps_completed_in_obv_period < self.observation_period_threshold:\n",
    "                    self.game_controls.end_the_game_and_start_a_new_one()\n",
    "                    self.start_exploration_in_observation_period(resuming)\n",
    "\n",
    "#                 self.game_controls.end_the_game_and_start_a_new_one()\n",
    "        print(' ')\n",
    "        print(' final count is ' + str(self.game_controls.img_count))\n",
    "        self.game_controls.end_the_game_and_start_a_new_one()\n",
    "        print('exploration period ended')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    If snake failed to eat any apple in the past P steps, it receives a negative as a punishment\n",
    "    '''\n",
    "#     def check_and_apply_negative_reward_if_snake_not_eat_apple_for_p_steps(self):\n",
    "        \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        imgs_count = self.check_for_in_screenshots_and_get_images_count()\n",
    "#         obsv_period_steps_completed = self.check_the_num_of_steps_completed_in_observation_period()\n",
    "        \n",
    "        print(self.from_index_to_add_exp_buffer_1, self.from_index_to_add_exp_buffer_2)\n",
    "        \n",
    "        self.restore_checkpoint()\n",
    "        epochs_completed = self.checkpoint.curr_epoch.numpy()\n",
    "        epochs_remaining = config.NUM_EPOCHS - epochs_completed - 1\n",
    "        \n",
    "#         self.game_controls.end_the_game()\n",
    "#         self.game_controls    = Game_functions()\n",
    "        self.game_controls.img_count = imgs_count\n",
    "        loss_log = tf.keras.metrics.Mean('perc_loss', dtype = tf.float32)\n",
    "        for epoch in range(epochs_remaining):\n",
    "            \n",
    "            \n",
    "            print('epoch ' + str(epoch))\n",
    "            if epoch != 0:\n",
    "                self.game_controls.end_the_game_and_start_a_new_one()\n",
    "            curr_epoch = self.checkpoint.curr_epoch.numpy()\n",
    "            self.game_controls.get_curr_state_of_the_game()\n",
    "#             self.game_controls    = Game_functions()\n",
    "            curr_state_imgs_paths = self.game_controls.curr_screenshots_paths.copy()\n",
    "            curr_reward           = self.game_controls.curr_reward\n",
    "            end_game              = self.game_controls.end_game\n",
    "#             curr_state           = self.preprocess_and_stack_images(curr_game_imgs_paths)\n",
    "            is_training_start = False\n",
    "            '''If the current state is not terminal i.e. not end_game'''\n",
    "            while not end_game: \n",
    "                action_to_be_taken = self.epsilon_greedy_policy_for_action(curr_state_imgs_paths)\n",
    "                next_state_imgs_paths, curr_reward, end_game, start_training_gap_period = self.perform_a_step_in_an_episode(action_to_be_taken)\n",
    "                \n",
    "                self.add_experiences_to_buffers_after_running_game_for_one_step(action_to_be_taken, curr_state_imgs_paths.copy(),\n",
    "                                                                                    self.game_controls.curr_screenshots_paths.copy(),\n",
    "                                                                                    self.game_controls.curr_reward,\n",
    "                                                                                    self.game_controls.end_game)\n",
    "                curr_state_imgs_paths = self.game_controls.curr_screenshots_paths.copy()\n",
    "\n",
    "\n",
    "\n",
    "                '''Train the model on random samples from both the experience buffers'''\n",
    "                self.adjust_buffer_sample_rate(epoch)\n",
    "                buffer_1_samples, buffer_2_samples = self.sample_mini_batches_from_experience_buffers()\n",
    "                buffer_samples = buffer_1_samples + buffer_2_samples\n",
    "                loss = self.train_step(buffer_samples)\n",
    "                loss_log.update_state(loss)\n",
    "#                 print('this episode finished')\n",
    "    \n",
    "                    \n",
    "            \n",
    "            if curr_epoch % 1 == 0:\n",
    "                self.save_buffer_experiences_as_npy_files_periodically()\n",
    "                self.checkpoint_manager.save()\n",
    "                print('In epoch ' + str(curr_epoch) + ' the loss is ' + str(loss_log.result()))\n",
    "                loss_log.reset_states()\n",
    "\n",
    "\n",
    "            if curr_epoch == config.NUM_EPOCHS - 1:\n",
    "                self.checkpoint.model.save_weights(config.FINAL_WEIGHTS_DIR + 'snake_game_weights.h5')\n",
    "                self.save_buffer_experiences_as_npy_files_periodically()\n",
    "                self.game_controls.end_the_game()\n",
    "\n",
    "\n",
    "            if curr_epoch != config.NUM_EPOCHS - 1:\n",
    "                self.checkpoint.curr_epoch.assign_add(1)\n",
    "            \n",
    "#             if end_game:\n",
    "#                 self.game_controls.end_the_game_and_start_a_new_one()\n",
    "#                 self.game_controls.new_game = True\n",
    "#                 self.game_controls.set_up_the_screen(False)\n",
    "                    \n",
    "#         except Exception:\n",
    "#             self.game_controls.end_the_game()\n",
    "#             traceback.print_exc()\n",
    "                \n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of steps completed are 1\n",
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 0\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 0\n",
      "26 0\n",
      "27 0\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 0\n",
      "32 0\n",
      "33 0\n",
      "34 0\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n",
      "43 0\n",
      "44 0\n",
      "45 0\n",
      "46 0\n",
      "47 0\n",
      "48 0\n",
      "49 0\n",
      "50 0\n",
      "51 0\n",
      "52 0\n",
      "53 0\n",
      "54 0\n",
      "55 0\n",
      "56 0\n",
      "57 0\n",
      "58 0\n",
      "59 0\n",
      "60 0\n",
      "61 0\n",
      "62 0\n",
      "63 0\n",
      "64 0\n",
      "65 0\n",
      "66 0\n",
      "67 0\n",
      "68 0\n",
      "69 0\n",
      "70 0\n",
      "71 0\n",
      "72 0\n",
      "73 0\n",
      "74 0\n",
      "75 0\n",
      "76 0\n",
      "77 0\n",
      "78 0\n",
      "79 0\n",
      "80 0\n",
      "81 0\n",
      "82 0\n",
      "83 0\n",
      "84 0\n",
      "85 0\n",
      "86 0\n",
      "87 0\n",
      "88 0\n",
      "89 0\n",
      "90 0\n",
      "91 0\n",
      "92 0\n",
      "93 0\n",
      "94 0\n",
      "95 0\n",
      "96 0\n",
      "97 0\n",
      "98 0\n",
      "99 0\n",
      "100 0\n",
      "101 0\n",
      "102 0\n",
      "103 0\n",
      "104 0\n",
      "105 0\n",
      "106 0\n",
      "107 0\n",
      "108 0\n",
      "109 0\n",
      "110 0\n",
      "111 0\n",
      "112 0\n",
      "113 0\n",
      "114 0\n",
      "115 0\n",
      "116 0\n",
      "117 0\n",
      "118 0\n",
      "119 0\n",
      "120 0\n",
      "121 0\n",
      "122 0\n",
      "123 0\n",
      "124 0\n",
      "125 0\n",
      "126 0\n",
      "127 0\n",
      "128 0\n",
      "129 0\n",
      "130 0\n",
      "131 0\n",
      "132 0\n",
      "133 0\n",
      "134 0\n",
      "135 0\n",
      "136 0\n",
      "137 0\n",
      "138 0\n",
      "139 0\n",
      "140 0\n",
      "141 0\n",
      "142 0\n",
      "143 0\n",
      "144 0\n",
      "145 0\n",
      "146 0\n",
      "147 0\n",
      "148 0\n",
      "149 0\n",
      "150 0\n",
      "151 0\n",
      "152 0\n",
      "153 0\n",
      "154 0\n",
      "155 0\n",
      "156 0\n",
      "157 0\n",
      "158 0\n",
      "159 0\n",
      "160 0\n",
      "161 0\n",
      "162 0\n",
      "163 0\n",
      "164 0\n",
      "165 0\n",
      "166 0\n",
      "167 0\n",
      "168 0\n",
      "169 0\n",
      "170 0\n",
      "171 0\n",
      "172 0\n",
      "173 0\n",
      "174 0\n",
      "175 0\n",
      "176 0\n",
      "177 0\n",
      "178 0\n",
      "179 0\n",
      "180 0\n",
      "181 0\n",
      "182 0\n",
      "183 0\n",
      "184 0\n",
      "185 0\n",
      "186 0\n",
      "187 0\n",
      "188 0\n",
      "189 0\n",
      "190 0\n",
      "191 0\n",
      "192 0\n",
      "193 0\n",
      "194 0\n",
      "195 0\n",
      "196 0\n",
      "197 0\n",
      "198 0\n",
      "199 0\n",
      "200 0\n",
      "201 0\n",
      "202 0\n",
      "203 0\n",
      "204 0\n",
      "205 0\n",
      "206 0\n",
      "207 0\n",
      "208 0\n",
      "209 0\n",
      "210 0\n",
      "211 0\n",
      "212 0\n",
      "213 0\n",
      "214 0\n",
      "215 0\n",
      "216 0\n",
      "217 0\n",
      "218 0\n",
      "219 0\n",
      "220 0\n",
      "221 0\n",
      "222 0\n",
      "223 0\n",
      "224 0\n",
      "225 0\n",
      "226 0\n",
      "227 0\n",
      "228 0\n",
      "229 0\n",
      "230 0\n",
      "231 0\n",
      "232 0\n",
      "233 0\n",
      "234 0\n",
      "235 0\n",
      "236 0\n",
      "237 0\n",
      "238 0\n",
      "239 0\n",
      "240 0\n",
      "241 0\n",
      "242 0\n",
      "243 0\n",
      "244 0\n",
      "245 0\n",
      "246 0\n",
      "247 0\n",
      "248 0\n",
      "249 0\n",
      "250 0\n",
      "251 0\n",
      "252 0\n",
      "253 0\n",
      "254 0\n",
      "255 0\n",
      "256 0\n",
      "257 0\n",
      "258 0\n",
      "259 0\n",
      "260 0\n",
      "261 0\n",
      "262 0\n",
      "263 0\n",
      "264 0\n",
      "265 0\n",
      "266 0\n",
      "267 0\n",
      "268 0\n",
      "269 0\n",
      "270 0\n",
      "271 0\n",
      "272 0\n",
      "273 0\n",
      "274 0\n",
      "275 0\n",
      "276 0\n",
      "277 0\n",
      "278 0\n",
      "279 0\n",
      "280 0\n",
      "281 0\n",
      "282 0\n",
      "283 0\n",
      "284 0\n",
      "285 0\n",
      "286 0\n",
      "287 0\n",
      "288 0\n",
      "289 0\n",
      "290 0\n",
      "291 0\n",
      "292 0\n",
      "293 0\n",
      "294 0\n",
      "295 0\n",
      "296 0\n",
      "297 0\n",
      "298 0\n",
      "299 0\n",
      "300 0\n",
      "301 0\n",
      "302 0\n",
      "303 0\n",
      "304 0\n",
      "305 0\n",
      "306 0\n",
      "307 0\n",
      "308 0\n",
      "309 0\n",
      "310 0\n",
      "311 0\n",
      "312 0\n",
      "313 0\n",
      "314 0\n",
      "315 0\n",
      "316 0\n",
      "317 0\n",
      "318 0\n",
      "319 0\n",
      "320 0\n",
      "321 0\n",
      "322 0\n",
      "323 0\n",
      "324 0\n",
      "325 0\n",
      "326 0\n",
      "327 0\n",
      "328 0\n",
      "329 0\n",
      "330 0\n",
      "331 0\n",
      "332 0\n",
      "333 0\n",
      "334 0\n",
      "335 0\n",
      "336 0\n",
      "337 0\n",
      "338 0\n",
      "339 0\n",
      "340 0\n",
      "341 0\n",
      "342 0\n",
      "343 0\n",
      "344 0\n",
      "345 0\n",
      "346 0\n",
      "347 0\n",
      "348 0\n",
      "349 0\n",
      "350 0\n",
      "351 0\n",
      "352 0\n",
      "353 0\n",
      "354 0\n",
      "355 0\n",
      "356 0\n",
      "357 0\n",
      "358 0\n",
      "359 0\n",
      "360 0\n",
      "361 0\n",
      "362 0\n",
      "363 0\n",
      "364 0\n",
      "365 0\n",
      "366 0\n",
      "367 0\n",
      "368 0\n",
      "369 0\n",
      "370 0\n",
      "371 0\n",
      "372 0\n",
      "373 0\n",
      "374 0\n",
      "375 0\n",
      "376 0\n",
      "377 0\n",
      "378 0\n",
      "379 0\n",
      "380 0\n",
      "381 0\n",
      "382 0\n",
      "383 0\n",
      "384 0\n",
      "385 0\n",
      "386 0\n",
      "387 0\n",
      "388 0\n",
      "389 0\n",
      "390 0\n",
      "391 0\n",
      "392 0\n",
      "393 0\n",
      "394 0\n",
      "395 0\n",
      "396 0\n",
      "397 0\n",
      "398 0\n",
      "399 0\n",
      "400 0\n",
      "401 0\n",
      "402 0\n",
      "403 0\n",
      "404 0\n",
      "405 0\n",
      "406 0\n",
      "407 0\n",
      "408 0\n",
      "409 0\n",
      "410 0\n",
      "411 0\n",
      "412 0\n",
      "413 0\n",
      "414 0\n",
      "415 0\n",
      "416 0\n",
      "417 0\n",
      "418 0\n",
      "419 0\n",
      "420 0\n",
      "421 0\n",
      "422 0\n",
      "423 0\n",
      "424 0\n",
      "425 0\n",
      "426 0\n",
      "427 0\n",
      "428 0\n",
      "429 0\n",
      "430 0\n",
      "431 0\n",
      "432 0\n",
      "433 0\n",
      "434 0\n",
      "435 0\n",
      "436 0\n",
      "437 0\n",
      "438 0\n",
      "439 0\n",
      "440 0\n",
      "441 0\n",
      "442 0\n",
      "443 0\n",
      "444 0\n",
      "445 0\n",
      "446 0\n",
      "447 0\n",
      "448 0\n",
      "449 0\n",
      "450 0\n",
      "451 0\n",
      "452 0\n",
      "453 0\n",
      "454 0\n",
      "455 0\n",
      "456 0\n",
      "457 0\n",
      "458 0\n",
      "459 0\n",
      "460 0\n",
      "461 0\n",
      "462 0\n",
      "463 0\n",
      "464 0\n",
      "465 0\n",
      "466 0\n",
      "467 0\n",
      "468 0\n",
      "469 0\n",
      "470 0\n",
      "471 0\n",
      "472 0\n",
      "473 0\n",
      "474 0\n",
      "475 0\n",
      "476 0\n",
      "477 0\n",
      "478 0\n",
      "479 0\n",
      "480 0\n",
      "481 0\n",
      "482 0\n",
      "483 0\n",
      "484 0\n",
      "485 0\n",
      "486 0\n",
      "487 0\n",
      "488 0\n",
      "489 0\n",
      "490 0\n",
      "491 0\n",
      "492 0\n",
      "493 0\n",
      "494 0\n",
      "495 0\n",
      "496 0\n",
      "497 0\n",
      "498 0\n",
      "499 0\n",
      "500 0\n",
      "501 0\n",
      "502 0\n",
      "503 0\n",
      "504 0\n",
      "505 0\n",
      "506 0\n",
      "507 0\n",
      "508 0\n",
      "509 0\n",
      "510 0\n",
      "511 0\n",
      "512 0\n",
      "513 0\n",
      "514 0\n",
      "515 0\n",
      "516 0\n",
      "517 0\n",
      "518 0\n",
      "519 0\n",
      "520 0\n",
      "521 0\n",
      "522 0\n",
      "523 0\n",
      "524 0\n",
      "525 0\n",
      "526 0\n",
      "527 0\n",
      "528 0\n",
      "529 0\n",
      "530 0\n",
      "531 0\n",
      "532 0\n",
      "533 0\n",
      "534 0\n",
      "535 0\n",
      "536 0\n",
      "537 0\n",
      "538 0\n",
      "539 0\n",
      "540 0\n",
      "541 0\n",
      "542 0\n",
      "543 0\n",
      "544 0\n",
      "545 0\n",
      "546 0\n",
      "547 0\n",
      "548 0\n",
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 0\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 0\n",
      "26 0\n",
      "27 0\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 0\n",
      "32 0\n",
      "33 0\n",
      "34 0\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n",
      "43 0\n",
      "npy files saved and 599 steps completed\n",
      "44 0\n",
      " \n",
      " final count is 589\n",
      "exploration period ended\n"
     ]
    }
   ],
   "source": [
    "'''If we are starting game (and so observation period) from start then resuming should be False\n",
    "else, True'''\n",
    "resuming = False \n",
    "train_snake_game = Training()\n",
    "train_snake_game.observation_period(resuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 142\n",
      "No checkpoint restoration\n",
      "epoch 0\n",
      "0 142\n",
      "1 142\n",
      "2 142\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a65b11aa43eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_snake_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-aa9b02c1755a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mnext_state_imgs_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_game\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_training_gap_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_a_step_in_an_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_to_be_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 self.add_experiences_to_buffers_after_running_game_for_one_step(action_to_be_taken, curr_state_imgs_paths.copy(),\n\u001b[0m\u001b[1;32m    559\u001b[0m                                                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_screenshots_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_reward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-aa9b02c1755a>\u001b[0m in \u001b[0;36madd_experiences_to_buffers_after_running_game_for_one_step\u001b[0;34m(self, action, curr_state_imgs_paths, next_state_imgs_paths, reward_after_action, end_game)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences_buffer_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_state_imgs_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_after_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_imgs_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_game\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences_buffer_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_index_to_add_exp_buffer_2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurr_state_imgs_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_after_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_imgs_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_game\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_index_to_add_exp_buffer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_index_to_add_exp_buffer_2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "train_snake_game.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file = np.load('/Users/vijay/Downloads/Code_Data/snake_game/npy_files/buffer_1_npy.npy', allow_pickle = True)\n",
    "filee = np.load('/Users/vijay/Downloads/Code_Data/snake_game/npy_files/buffer_2_npy.npy', allow_pickle = True)\n",
    "print(len(file), len(filee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in file:\n",
    "    print(p)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('/Users/vijay/Downloads/Code_Data/snake_game/screenshots/')\n",
    "files = [file for file in files if 'DS' not in file]\n",
    "if len(files) != 0:\n",
    "    '''Sort the image names using the integer part'''\n",
    "    files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    recent_img_name = files[-1]\n",
    "    match_object = re.search('\\D', recent_img_name)\n",
    "    num = int(recent_img_name[0:match_object.start()])\n",
    "    print(num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
