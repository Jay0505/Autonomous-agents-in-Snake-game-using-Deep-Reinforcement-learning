{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev6 (SDL 2.0.10, python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pygame\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pygame.locals import *\n",
    "pygame.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Input, Flatten, Dense, Lambda, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict()\n",
    "\n",
    "config.CHECKPOINT_DIR = '/Users/vijay/Downloads/ew/snake_game_ckpts/'\n",
    "config.NUM_EPOCHS     = 5000\n",
    "config.BATCH_SIZE     = 64\n",
    "config.EPSILON        = 0.9\n",
    "config.BUFFER_SAMPLE_RATE = 0.8\n",
    "config.BUFFER_SAMPLE_RATE_DECAY_RATE = 0.1\n",
    "config.DISCOUNT_FACTOR = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/vijay/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Collecting easydict\n",
      "  Using cached easydict-1.9.tar.gz (6.4 kB)\n",
      "Building wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6349 sha256=0d170b5408d5498114f0cf5ae435b42d96d9040b0f85585736a168f03f44adf8\n",
      "  Stored in directory: /Users/vijay/Library/Caches/pip/wheels/d3/e0/e9/305e348717e399665119bd012510d51ff4f22d709ff60c3096\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pygame in /Users/vijay/.local/lib/python3.8/site-packages (2.0.0.dev6)\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install opencv-python\n",
    "# !{sys.executable} -m pip install pygame\n",
    "!python3 -m pip install pygame -U --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev6 (SDL 2.0.10, python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settings:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.screen_color = (100, 100, 100)\n",
    "        self.screen_width = 200\n",
    "        self.screen_height = 200\n",
    "        self.run_game = True\n",
    "        self.snake_nodes_group = []\n",
    "        \n",
    "        \n",
    "class Snake_Node:\n",
    "    def __init__(self, node_num, x, y, color, radius):\n",
    "        \n",
    "        self.snake_node_num = node_num\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.radius = radius\n",
    "        self.direction = 'up'\n",
    "        \n",
    "    def draw_snake_node(self, screen):\n",
    "#         snake_node = pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius)\n",
    "        snake_node = pygame.draw.rect(screen, self.color, (self.x, self.y, 10, 10), 1)\n",
    "        return snake_node\n",
    "    \n",
    "    \n",
    "    \n",
    "class Snake_Head:\n",
    "    def __init__(self, x, y, color, radius):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.radius = radius\n",
    "#         self.moving_direction = 'up'\n",
    "    \n",
    "    def draw_snake_head(self, screen):\n",
    "        snake_head = pygame.draw.rect(screen, self.color, (self.x, self.y, 10, 10))\n",
    "#         snake_head = pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius)\n",
    "        return snake_head\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Game_functions:\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_of_steps_in_curr_episode = 0\n",
    "        self.start_training_gap_period = False\n",
    "        self.is_apple_there = False\n",
    "        self.game_settings = settings()\n",
    "        self.divide_screen_into_segments()\n",
    "        self.num_of_snake_nodes = 0\n",
    "        self.snake_head_moving_direction = ' '\n",
    "        self.xy_list = []\n",
    "        self.radius = 10\n",
    "        self.rect_width = 5\n",
    "        self.rect_height = 5\n",
    "        self.full_reward = 0\n",
    "#         self.full_reward = False\n",
    "        self.img_count = 0\n",
    "        self.prev_distance = -1\n",
    "        self.new_game = True\n",
    "        self.score    = 0\n",
    "        self.img_dir  = '/Users/vijay/Downloads/ew/'\n",
    "        \n",
    "        self.set_up_the_screen()\n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def divide_screen_into_segments(self):\n",
    "        self.segment_indices = []\n",
    "        for i in range(0, 200):\n",
    "            if i % 10 == 0:\n",
    "                self.segment_indices.append(i)\n",
    "                \n",
    "                \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def draw_snake_nodes_xy(self, from_list):\n",
    "        \n",
    "        if from_list:\n",
    "            for index, xy_tuple in enumerate(self.xy_list):\n",
    "                if index != 0:\n",
    "                    self.create_snake_head_or_apple(xy_tuple[0], xy_tuple[1], 5, False)\n",
    "                    pygame.display.update()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def get_new_xy_for_apple(self):\n",
    "        x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "        if (x, y) not in self.xy_list:\n",
    "            return x, y\n",
    "        else:\n",
    "            return self.get_new_xy_for_apple()\n",
    "        \n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def create_snake_head_or_apple(self, x, y, is_apple):\n",
    "        \n",
    "        if not is_apple:\n",
    "            color = (255,255,255)\n",
    "            \n",
    "            if self.num_of_snake_nodes != 0:\n",
    "                \n",
    "                snake_node_obj = Snake_Node(self.num_of_snake_nodes, x, y, color, self.radius)\n",
    "                snake_node = snake_node_obj.draw_snake_node(self.screen)\n",
    "                \n",
    "                \n",
    "            elif self.num_of_snake_nodes == 0:\n",
    "                snake_head_obj = Snake_Head(x, y, (0, 255, 0), self.radius)\n",
    "                self.snake_head = snake_head_obj.draw_snake_head(self.screen)\n",
    "\n",
    "                \n",
    "            self.num_of_snake_nodes = self.num_of_snake_nodes + 1\n",
    "            \n",
    "            if self.num_of_snake_nodes < 5:\n",
    "                pygame.time.wait(80)\n",
    "            else:\n",
    "                pygame.time.wait(10)\n",
    "            \n",
    "        if is_apple:\n",
    "            color = (255, 0, 0)\n",
    "            self.apple = pygame.draw.rect(self.screen, color, (x, y, 10, 10))\n",
    "#             self.apple = pygame.draw.circle(self.screen, color, (x, y), self.radius)\n",
    "            self.is_apple_there = True\n",
    "            self.apple_x = x\n",
    "            self.apple_y = y\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def start_a_new_game(self):\n",
    "#         print('start a new game')\n",
    "        if self.new_game:\n",
    "            self.is_apple_there     = False\n",
    "            self.num_of_snake_nodes = 0\n",
    "            self.xy_list.clear()\n",
    "            self.screen.fill((100, 100, 100))\n",
    "            self.prev_distance      = -1\n",
    "#             self.img_count          = 0\n",
    "            self.full_reward        = 0\n",
    "            self.score              = 0\n",
    "            \n",
    "            x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "            self.xy_list.append((x, y))\n",
    "            self.draw_rect_at_new_location()\n",
    "            self.new_game           = False\n",
    "#             self.set_up_the_screen()\n",
    "\n",
    "    ####################################\n",
    "    \n",
    "    def check_if_snake_is_at_boundaries(self, new_x, new_y, direction):\n",
    "\n",
    "        if direction == 'up':\n",
    "            if new_y  < 0:\n",
    "                print('wall')\n",
    "                return True\n",
    "    \n",
    "\n",
    "        elif direction == 'down':\n",
    "            if new_y  > self.game_settings.screen_width:\n",
    "                print('wall')\n",
    "                return True\n",
    "    \n",
    "\n",
    "        elif direction == 'left':\n",
    "            if new_x  < 0:\n",
    "                print('wall')\n",
    "                return True\n",
    "  \n",
    "\n",
    "        elif direction == 'right':\n",
    "            if new_x  > self.game_settings.screen_width:\n",
    "                print('wall')\n",
    "                return True\n",
    "        \n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####################################\n",
    "\n",
    "    def draw_rect_at_new_location(self):\n",
    "        \n",
    "        self.screen.fill((100, 100, 100))\n",
    "        self.num_of_snake_nodes = 0\n",
    "        \n",
    "        for xy_tuple in self.xy_list:        \n",
    "            self.create_snake_head_or_apple(xy_tuple[0], xy_tuple[1], False)\n",
    "    \n",
    "        \n",
    "        self.create_apple()\n",
    "        pygame.display.update()\n",
    "\n",
    "\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def get_new_x_y_for_moving(self, x, y, direction):\n",
    "        \n",
    "        if direction == 'up':\n",
    "            y = y - self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'down':\n",
    "            y = y + self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'left':\n",
    "            x = x - self.radius\n",
    "            \n",
    "\n",
    "        elif direction == 'right':\n",
    "            x = x + self.radius\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "#     ###################################\n",
    "    \n",
    "    def move_nodes(self, head_direction):\n",
    "        prev_tuple = (-1, -1)\n",
    "        curr_tuple = (-1, -1)\n",
    "        for index, xy_tuple in enumerate(self.xy_list):\n",
    "            if index == 0:\n",
    "                prev_tuple = xy_tuple\n",
    "            elif index != 0:\n",
    "                curr_tuple = self.xy_list[index]\n",
    "                self.xy_list[index] = prev_tuple\n",
    "                prev_tuple = curr_tuple\n",
    "        \n",
    "    \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def check_if_snake_ran_into_its_own_body(self):\n",
    "        \n",
    "        tuple_counter = Counter(self.xy_list)\n",
    "        if tuple_counter[self.xy_list[0]] != 1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    " \n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    def move_snake_head_new(self, direction):\n",
    "        \n",
    "        '''\n",
    "        First, get the new xy for the snake head to move\n",
    "        check whether the snake head is at the boundaries wrt new xy\n",
    "        if not, get new xy for all the snake nodes \n",
    "        update the xy_list with all the new xy values of both nodes and head\n",
    "        after updating, check, after moving, if the head bumped into its own body\n",
    "        '''\n",
    "        x, y = self.xy_list[0][0], self.xy_list[0][1]\n",
    "        new_x, new_y = self.get_new_x_y_for_moving(x, y, direction)\n",
    "        is_snake_at_boundary = self.check_if_snake_is_at_boundaries(new_x, new_y, direction)\n",
    "\n",
    "        if not is_snake_at_boundary:\n",
    "            \n",
    "            self.move_nodes(direction)\n",
    "            self.xy_list[0] = (new_x, new_y)\n",
    "            snake_ran_into_its_own_body = self.check_if_snake_ran_into_its_own_body()\n",
    "            if not snake_ran_into_its_own_body:\n",
    "                self.new_game = False\n",
    "                self.draw_rect_at_new_location()\n",
    "            else:\n",
    "                '''\n",
    "                if the snake bumped into its own body, then a reward of -1 has to be given to the snake\n",
    "                '''\n",
    "                self.full_reward = -1\n",
    "                self.new_game    = True\n",
    "                self.end_game()\n",
    "#                 self.start_a_new_game()\n",
    "\n",
    "        else:\n",
    "            '''\n",
    "            if the snake bumped into any boundary, then a reward of -1 has to be given to the snake\n",
    "            '''\n",
    "            self.full_reward = -1\n",
    "            self.new_game    = True\n",
    "            self.end_game()\n",
    "#             self.start_a_new_game()\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    ####################################\n",
    "    \n",
    "    def create_apple(self):\n",
    "        \n",
    "        if not self.is_apple_there:\n",
    "            x, y = self.get_new_xy_for_apple()\n",
    "#             x, y = random.choice(self.segment_indices),random.choice(self.segment_indices)\n",
    "            \n",
    "            self.create_snake_head_or_apple(x, y, True)\n",
    "        \n",
    "        if self.is_apple_there:\n",
    "            self.create_snake_head_or_apple(self.apple_x, self.apple_y, True)\n",
    "            \n",
    "        pygame.display.update()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    '''\n",
    "    if an action is supplied (direction) and in that direction, if there is a node in that direction, then stop moving it\n",
    "    \n",
    "    '''\n",
    "    def check_whether_to_move_nodes_or_not(self, direction):\n",
    "        if direction == 'up':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] and self.xy_list[0][1] == self.xy_list[1][1] + self.radius:\n",
    "                return False\n",
    "        \n",
    "        elif direction == 'down':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] and self.xy_list[0][1] == self.xy_list[1][1] - self.radius:\n",
    "                return False\n",
    "        \n",
    "        elif direction == 'left':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] + self.radius and self.xy_list[0][1] == self.xy_list[1][1]:\n",
    "                return False\n",
    "            \n",
    "        elif direction == 'right':\n",
    "            if self.xy_list[0][0] == self.xy_list[1][0] - self.radius and self.xy_list[0][1] == self.xy_list[1][1]:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    def get_new_xy_for_new_node_after_eating_apple(self):\n",
    "        \n",
    "        last_node_x, last_node_y = self.xy_list[-1][0], self.xy_list[-1][1]\n",
    "        new_x, new_y = -1, -1\n",
    "        \n",
    "        if last_node_x + self.radius < self.game_settings.screen_width:\n",
    "            if (last_node_x + self.radius, last_node_y) not in self.xy_list: \n",
    "                new_x = last_node_x + self.radius\n",
    "                new_y = last_node_y\n",
    "        \n",
    "        elif last_node_x - self.radius > 0:\n",
    "            if (last_node_x - self.radius, last_node_y) not in self.xy_list:\n",
    "                new_x = last_node_x - self.radius\n",
    "                new_y = last_node_y\n",
    "        \n",
    "        \n",
    "        elif last_node_y - self.radius > 0 :\n",
    "            if (last_node_x, last_node_y - self.radius) not in self.xy_list: \n",
    "                new_x = last_node_x\n",
    "                new_y = last_node_y -self.radius5\n",
    "            \n",
    "        elif last_node_y + self.radius < self.game_settings.screen_width:\n",
    "            if (last_node_x, last_node_y + self.radius) not in self.xy_list:\n",
    "                new_x = last_node_x\n",
    "                new_y = last_node_y + self.radius\n",
    "            \n",
    "        \n",
    "        return new_x, new_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    def add_just_eaten_apple_to_the_snake_end(self):\n",
    "        \n",
    "        new_node_x, new_node_y = self.get_new_xy_for_new_node_after_eating_apple()\n",
    "        self.xy_list.append((new_node_x, new_node_y))\n",
    "        self.is_apple_there = False\n",
    "        self.draw_rect_at_new_location()\n",
    "        self.start_training_gap_period = True\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################\n",
    "    \n",
    "    '''\n",
    "    if apple's xy and snake_head's xy (first value in xy_list), then we consider that snake has eaten apple\n",
    "    '''\n",
    "    def is_apple_eaten(self):\n",
    "        \n",
    "        if self.is_apple_there:\n",
    "            if self.apple_x == self.xy_list[0][0] and self.apple_y == self.xy_list[0][1]:\n",
    "                '''\n",
    "                if apple is eaten, a full reward of 1 has to be given to the snake\n",
    "                '''\n",
    "                self.full_reward = 1\n",
    "                self.score = self.score + 10\n",
    "                self.add_just_eaten_apple_to_the_snake_end()\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def check_if_snake_moved_closer_to_apple(self):\n",
    "        \n",
    "        snake_head_xy = self.xy_list[0]\n",
    "        apple_xy      = (self.apple_x, self.apple_y)\n",
    "        \n",
    "        curr_distance = math.sqrt( ((snake_head_xy[0] - apple_xy[0]) ** 2) + ((snake_head_xy[1] - apple_xy[1]) ** 2))\n",
    "        \n",
    "        if self.prev_distance == -1:\n",
    "            self.prev_distance = curr_distance\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            if curr_distance < self.prev_distance:\n",
    "                return True\n",
    "            else: \n",
    "                False\n",
    "        \n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    def get_reward(self):\n",
    "        '''\n",
    "        -- if snake_head moved towards apple, reward = 0.2\n",
    "        --                            if not, reward = -0.2\n",
    "        --- if snake bumped into its own body or bumped into boundaries, reward = -1\n",
    "        --- if snake eats apple, reward = 1\n",
    "        --- if snake cannot move, then reward = -0.1\n",
    "        '''\n",
    "        if self.full_reward == 0:\n",
    "            moved_closer = self.check_if_snake_moved_closer_to_apple()\n",
    "            if moved_closer:\n",
    "                return 0.2\n",
    "            \n",
    "            elif not moved_closer:\n",
    "                return -0.2\n",
    "        \n",
    "        else:\n",
    "            return self.full_reward\n",
    "        \n",
    "#         elif self.full_reward == -0.1:\n",
    "#             return -0.1\n",
    "            \n",
    "#         elif self.full_reward == -1:\n",
    "#             return -1\n",
    "        \n",
    "#         elif self.full_reward == 1:\n",
    "#             return 1\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    def get_curr_state_of_the_game(self):\n",
    "        \n",
    "        '''\n",
    "        -- Stacking last 4 screenshots of the image as one\n",
    "        -- if the num of screenshots is less than 4, then the last screenshot has to be appended \n",
    "            required num of times\n",
    "        --- if the num of screenshots is greater than 4, then the recent last 4 screenshots has to be \n",
    "            appended\n",
    "        '''\n",
    "        img_ids = []\n",
    "        if self.img_count <= 4:\n",
    "            for id in range(self.img_count - 1):\n",
    "                img_ids.append(id)\n",
    "            remaining = 4 - (self.img_count - 1)\n",
    "            for id in range(remaining):\n",
    "                img_ids.append(img_ids[-1])\n",
    "\n",
    "        else:\n",
    "            for id in range(4):\n",
    "                img_ids.append(self.img_count - (id + 1))\n",
    "        \n",
    "        img_ids.reverse()\n",
    "        \n",
    "        for id in img_ids:\n",
    "            self.curr_screenshots_paths.append(self.img_dir + str(id) + '.jpg')\n",
    "        reward = self.get_reward()        \n",
    "        end_game = self.new_game\n",
    "        \n",
    "#         self.curr_screenshot_path = curr_screenshot_path\n",
    "        self.curr_reward = reward\n",
    "        self.end_game    = end_game\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    ###################################    \n",
    "        \n",
    "    def set_up_the_screen(self):\n",
    "        pygame.display.init()\n",
    "        self.screen = pygame.display.set_mode((self.game_settings.screen_width, self.game_settings.screen_height))\n",
    "        pygame.display.flip()\n",
    "        self.start_a_new_game()\n",
    "        pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "        self.img_count = self.img_count + 1\n",
    "#         self.get_curr_state_of_the_game()\n",
    "        img_ids = []\n",
    "        curr_screenshot_path = self.img_dir + str(self.img_count - 1) + '.jpg'\n",
    "        for id in range(4):\n",
    "            img_ids.append(curr_screenshot_path)\n",
    "        \n",
    "        self.curr_screenshots_paths = img_ids\n",
    "        self.curr_reward = 0\n",
    "        self.end_game = False\n",
    "#         image = pygame.image.tostring(self.screen, 'RGB')\n",
    "#         cv2.imshow('img', image)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def end_the_game(self):\n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "        exit()\n",
    "        \n",
    "    ####################################\n",
    "    \n",
    "    def run(self, action):\n",
    "#         while self.game_settings.run_game:\n",
    "        try:\n",
    "            \n",
    "            apple_eaten = False\n",
    "            for event in pygame.event.get():\n",
    "\n",
    "                if event.type == QUIT:\n",
    "                    self.game_settings.run_game = False\n",
    "                    pygame.display.quit()\n",
    "                    pygame.quit()\n",
    "                    exit()\n",
    "            \n",
    "            if self.num_of_snake_nodes == 1:\n",
    "                move_nodes = True\n",
    "            \n",
    "            keys = pygame.key.get_pressed()\n",
    "            \n",
    "\n",
    "            ############\n",
    "#                 if keys[pygame.K_UP]:\n",
    "\n",
    "#                     action = 'up'\n",
    "#                     print(action)\n",
    "            if action == 'up':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "\n",
    "                if move_nodes:\n",
    "                    \n",
    "                    self.move_snake_head_new(action)\n",
    "                    pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "                    self.img_count = self.img_count + 1\n",
    "                    self.is_apple_eaten()\n",
    "\n",
    "\n",
    "            ##############\n",
    "#                 elif keys[pygame.K_DOWN]:\n",
    "#                     action = 'down'\n",
    "#                     print(action)\n",
    "            elif action == 'down':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "                    \n",
    "                    self.move_snake_head_new(action)\n",
    "                    pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "                    self.img_count = self.img_count + 1\n",
    "                    self.is_apple_eaten()\n",
    "\n",
    "\n",
    "            ##############\n",
    "#                 elif keys[pygame.K_LEFT]:\n",
    "#                     action = 'left'\n",
    "#                     print(action)\n",
    "            elif action == 'left':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "                    \n",
    "                    self.move_snake_head_new(action)\n",
    "                    pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "                    self.img_count = self.img_count + 1\n",
    "                    self.is_apple_eaten()\n",
    "\n",
    "\n",
    "\n",
    "            ###########\n",
    "#                 elif keys[pygame.K_RIGHT]:\n",
    "#                     action = 'right'\n",
    "#                     print(action)\n",
    "            elif action == 'right':\n",
    "                if self.num_of_snake_nodes > 1:\n",
    "                    move_nodes = self.check_whether_to_move_nodes_or_not(action)\n",
    "                    if not move_nodes:\n",
    "                        self.full_reward = -0.1\n",
    "\n",
    "                if move_nodes:\n",
    "\n",
    "                    self.move_snake_head_new(action)\n",
    "                    pygame.image.save(self.screen, self.img_dir + str(self.img_count) + '.jpg')\n",
    "                    self.img_count = self.img_count + 1\n",
    "                    self.is_apple_eaten()\n",
    "\n",
    "\n",
    "            pygame.display.flip()\n",
    "            self.get_curr_state_of_the_game()\n",
    "\n",
    "        except:\n",
    "            self.end_the_game()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# game_functions = Game_functions()\n",
    "# # game_functions.run('test')\n",
    "# for i in range(500):\n",
    "#     actions = ['up', 'left', 'right', 'down']\n",
    "#     action_index = random.randint(0, 3)\n",
    "#     action = actions[action_index]\n",
    "#     game_functions.run(action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Q_values_approximator_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def normalize_to_range_01(self, img):\n",
    "        return tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    def get_q_values(self):\n",
    "        input_data = Input(shape = (64, 64, 12))\n",
    "        data = Lambda(self.normalize_to_range_01)(input_data)\n",
    "        data = Conv2D(filters = 32, kernel_size = 7, strides = (4, 4), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Conv2D(filters = 64, kernel_size = 5, strides = (2, 2), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Conv2D(filters = 128, kernel_size = 3, strides = (2, 2), padding = 'SAME')(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Flatten()(data)\n",
    "        data = Dense(512)(data)\n",
    "        data = ReLU()(data)\n",
    "        \n",
    "        data = Dense(4)(data)\n",
    "        \n",
    "        return tf.keras.Model(input_data, data)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q_values_predictor = Q_values_approximator_model()\n",
    "in_data = np.arange(64 * 64*12).reshape(64, 64, 12)\n",
    "out_data = q_values_predictor.get_q_values()(np.expand_dims(in_data, axis = 0))\n",
    "print(out_data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training:\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.game_controls = Game_functions()\n",
    "        self.training_gap_steps = 0\n",
    "        self.experiences_buffer_1   = []\n",
    "        self.experiences_buffer_2 = []\n",
    "        self.observation_period_threshold = 5\n",
    "        self.num_of_steps_completed_in_obv_period = 0\n",
    "        self.actions = ['up', 'down', 'right', 'left']\n",
    "        \n",
    "        q_values_predictor = Q_values_approximator_model()\n",
    "        self.q_values_pred_model = q_values_predictor.get_q_values()\n",
    "        self.model_optimizer = Adam(learning_rate = 0.001)\n",
    "        self.checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "                                              model = self.q_values_pred_model, \n",
    "                                              optimizer = self.model_optimizer\n",
    "                                             )\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, \n",
    "                                                            directory = config.CHECKPOINT_DIR,\n",
    "                                                            max_to_keep = 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def preprocess_and_stack_images(self, curr_game_images_paths):\n",
    "        images = []\n",
    "        for image_path in curr_game_images_paths:\n",
    "            image = cv2.resize(cv2.imread(image_path), (64, 64))\n",
    "            images.append(image)\n",
    "        \n",
    "        stacked_images = np.concatenate((images[0], images[1], images[2], images[3]), axis = 2)\n",
    "        return stacked_images\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    After deciding upon action to be taken, run the game for one step\n",
    "    Then, collect the next state images paths, reward received and whether the next state is terminal\n",
    "    '''\n",
    "    def perform_a_step_in_an_episode(self, action):\n",
    "        \n",
    "        self.game_controls.run(action)\n",
    "        game_imgs_paths_after_action = self.game_controls.curr_screenshots_paths\n",
    "        reward_after_action = self.game_controls.curr_reward\n",
    "        end_game_after_action = self.game_controls.end_game\n",
    "        start_training_gap_period = self.start_training_gap_period\n",
    "        return game_imgs_paths_after_action, reward_after_action, end_game_after_action, start_training_gap_period\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def determing_num_of_training_gap_steps_after_snake_eating_apple(self):\n",
    "        length_of_snake = self.game_controls.score \n",
    "        k = 10\n",
    "        p = 0.4\n",
    "        q = 0.2\n",
    "        if length_of_snake <= k:\n",
    "            self.training_gap_steps = 6\n",
    "        elif length_of_snake > k:\n",
    "            self.training_gap_steps = math.ceil((p * length_of_snake) + q)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    --- Get an action and run the game as per the action\n",
    "    --- Now, record the updated state of the game by getting the curr screenshot of the screen, \n",
    "         current reward and also whether the current state resulted in quitting game which happens\n",
    "         when snake bumps into boundaries or ran into itself.\n",
    "\n",
    "    '''\n",
    "    def add_experiences_to_buffers_after_running_game_for_one_step(self, action, curr_state_imgs_paths):\n",
    "        \n",
    "        next_state_imgs_paths, reward_after_action, end_game, start_training_gap_period = self.perform_a_step_in_an_episode(action)\n",
    "        \n",
    "        if reward_after_action > 0:\n",
    "            self.experiences_buffer_1.append(curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game)\n",
    "\n",
    "        else:\n",
    "            self.experiences_buffer_2.append(curr_state_imgs_paths, action, reward_after_action, next_state_imgs_paths, end_game)\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        return next_state_imgs_paths, end_game, start_training_gap_period\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def start_exploration_in_observation_period(self):\n",
    "        \n",
    "        num_of_training_gap_steps_completed = 0\n",
    "        enter_training_gap_period = False\n",
    "        curr_state_imgs_paths = self.game_controls.curr_screenshots_paths\n",
    "        curr_reward           = self.game_controls.curr_reward\n",
    "        end_game              = self.game_controls.end_game\n",
    "        start_training_gap    = self.game_controls.start_training_gap_period\n",
    "#         curr_state           = self.preprocess_and_stack_images(curr_game_imgs_paths)\n",
    "        \n",
    "        \n",
    "        while self.num_of_steps_completed_in_obv_period < self.observation_period_threshold and not end_game:\n",
    "            \n",
    "            '''\n",
    "            -- so, when the snake eats an apple, then we should immediately enter into a training_gap_period during which no experiences are\n",
    "                stored into experience buffers.\n",
    "            \n",
    "            -- if start_training_gap and enter_training_gap_period == False, then we haven't entered the training_gap and therefore set\n",
    "                enter_training_gap_period = True\n",
    "            \n",
    "            -- if not start_training_gap, then add experiences to the buffer. if in training_gap_period, then just perform single step in the game\n",
    "                without storing experiences in the experience buffers. Also, increase the number of steps completed in trainig_gap_period\n",
    "            \n",
    "            -- if the num_of_steps in training_gap is equal to the pre-determined num_of_steps in training_gap_period, then exit training_gap_period\n",
    "                by setting enter_training_gap_period = False and self.game_controls.start_training_gap_period = False\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            if start_training_gap and not enter_training_gap_period:\n",
    "                enter_training_gap_period = True\n",
    "                self.determing_num_of_training_gap_steps_after_snake_eating_apple()\n",
    "            \n",
    "            if enter_training_gap_period and (num_of_training_gap_steps_completed == self.training_gap_steps - 1):\n",
    "                enter_training_gap_period = False\n",
    "                self.game_controls.start_training_gap_period = False\n",
    "            \n",
    "            action = self.actions[random.randint(0, 3)]\n",
    "#             next_state, end_game = self.add_experiences_to_buffers_after_running_game_for_one_step(action, curr_state)\n",
    "\n",
    "            if not enter_training_gap_period:\n",
    "        \n",
    "                next_state_imgs_paths, end_game, start_tranining_gap = self.add_experiences_to_buffers_after_running_game_for_one_step(action, curr_state_imgs_paths)\n",
    "                curr_state_imgs_paths = next_state_imgs_paths\n",
    "            \n",
    "            elif enter_training_gap_period:\n",
    "                \n",
    "                next_state_imgs_paths, reward_after_action, end_game, start_training_gap = self.perform_a_step_in_an_episode(action)\n",
    "                num_of_training_gap_steps_completed = num_of_training_gap_steps_completed + 1\n",
    "                curr_state_imgs_paths = next_state_imgs_paths\n",
    "                \n",
    "            self.num_of_steps_completed_in_obv_period = self.num_of_steps_completed_in_obv_period + 1\n",
    "            \n",
    "                \n",
    "        \n",
    "        \n",
    "    def restore_checkpoint(self):\n",
    "\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print('restored checkpoint successfully at epoch ' + str(self.checkpoint.curr_epoch.numpy()))\n",
    "        else:\n",
    "            print('No checkpoint restoration')\n",
    "\n",
    "\n",
    "\n",
    "    def epsilon_greedy_policy_for_action(self, curr_state_imgs_paths):\n",
    "        if random.random() < config.EPSILON:\n",
    "            return self.actions[random.randint(0, 3)]\n",
    "        else:\n",
    "            curr_state_imgs = self.preprocess_and_stack_images(curr_state_imgs_paths)\n",
    "            q_values = self.checkpoint.model(curr_state_imgs, training = False)\n",
    "            return self.actions[np.argmax(q_values)]\n",
    "\n",
    "\n",
    "\n",
    "    def adjust_buffer_sample_rate(self, epoch):\n",
    "        if epoch % 1000 == 0:\n",
    "            decay_value = config.BUFFER_SAMPLE_RATE * config.BUFFER_SAMPLE_RATE_DECAY_RATE\n",
    "            new_buffer_sample_rate = config.BUFFER_SAMPLE_RATE - decay_value\n",
    "            if not new_buffer_sample_rate > 0.5:\n",
    "                config.BUFFER_SAMPLE_RATE = new_buffer_sample_rate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def sample_mini_batches_from_experience_buffers(self):\n",
    "\n",
    "        num_samples_from_buffer_1 = int(64 * config.BUFFER_SAMPLE_RATE)\n",
    "        num_samples_from_buffer_2 = 64 - num_samples_from_buffer_1\n",
    "\n",
    "        random_samples_from_buffer_1 = random.sample(self.experiences_buffer_1, num_samples_from_buffer_1)\n",
    "        random_samples_from_buffer_2 = random.sample(self.experiences_buffer_2, num_samples_from_buffer_2)\n",
    "\n",
    "        return random_samples_from_buffer_1, random_samples_from_buffer_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_target_labels_for_samples(self, buffer_samples):\n",
    "        '''\n",
    "        experience[0] = curr_State_imgs_paths\n",
    "        experience[1] = action [This is a text 'up', 'down', 'left', 'right']\n",
    "        experience[2] = reward_after_action\n",
    "        experience[3] = next_state_imgs_paths\n",
    "        experience[4] = end_game\n",
    "        '''\n",
    "        label_values = []\n",
    "        for experience in buffer_samples:\n",
    "            if experience[4]: # is the episode reached terminal state - end_game\n",
    "                label_values.append(experience[2])\n",
    "\n",
    "            else:\n",
    "                next_state_imgs = self.preprocess_and_stack_images(experience[3])\n",
    "                q_values_of_actions = self.checkpoint.model(next_state_imgs)\n",
    "                print('predicted values in train_step ' + str(q_values_of_actions.numpy()))\n",
    "                target_value = experience[2] + (config.DISCOUNT_FACTOR * np.max(q_values_of_actions[0]))\n",
    "                label_values.append(target_value)\n",
    "\n",
    "        return label_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_actual_labels_for_samples(self, buffer_samples):\n",
    "        actual_labels = []\n",
    "        for experience in buffer_samples:\n",
    "            curr_state_imgs_paths = experience[0]\n",
    "            action = experience[1]\n",
    "            action_index = self.actions.index(action)\n",
    "\n",
    "            curr_state_imgs = self.preprocess_and_stack_images(curr_state_imgs_paths)\n",
    "\n",
    "            '''\n",
    "            here, when we run the model on the screenshot images, we get the q-values of action.\n",
    "            Once check whether we receive a list of list or just a list.\n",
    "            ex:- [[1, 2, 3, 4]] or [1, 2, 3, 4]\n",
    "            '''\n",
    "            curr_state_label = self.checkpoint.model(curr_state_imgs, training = False)[action_index]\n",
    "            actual_labels.append(curr_state_label)\n",
    "\n",
    "        return actual_labels\n",
    "\n",
    "\n",
    "    \n",
    "    def loss_function(self, target_labels, actual_labels):\n",
    "        return np.square(np.asarray(target_lables) - np.asarray(actual_labels))\n",
    "    \n",
    "    \n",
    "    def train_step(self):\n",
    "        target_label_values_for_samples = self.get_target_labels_for_samples(buffer_samples)\n",
    "        actual_label_values_for_samples = self.get_actual_labels_for_samples(buffer_samples)\n",
    "        \n",
    "        if len(target_label_values_for_samples) == len(actual_label_values_for_samples):\n",
    "            \n",
    "            with tf.GradientTape(persistent = True) as params_tape:\n",
    "                loss = self.loss_function(target_label_values_for_samples, actual_label_values_for_samples)\n",
    "            \n",
    "            model_gradients = params_tape.gradient(loss, self.checkpoint.model.trainable_variables)\n",
    "            self.checkpoint.optimizer.apply_gradients(zip(model_gradients, self.checkpoint.model.trainable_variables))\n",
    "            \n",
    "            return loss\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                print('there is a problem with the actual and target variables')\n",
    "                return -1\n",
    "    \n",
    "    \n",
    "\n",
    "    def train(self):\n",
    "        '''\n",
    "        For the first 50000 seteps, just let the agent choose random actions and explore very\n",
    "        extensively so tha it could have a vast experience buffer\n",
    "        '''\n",
    "        if self.num_of_steps_completed_in_obv_period < self.observation_period_threshold:\n",
    "            self.start_exploration_in_observation_period()\n",
    "\n",
    "        self.restore_checkpoint()\n",
    "        epochs_completed = self.checkpoint.curr_epoch.numpy()\n",
    "        epochs_remaining = config.NUM_EPOCHS - epochs_completed - 1\n",
    "\n",
    "        for epoch in range(epochs_remaining):\n",
    "            curr_epoch = self.checkpoint.curr_epoch.numpy()\n",
    "\n",
    "            self.game_controls    = Game_functions()\n",
    "            curr_state_imgs_paths = self.game_controls.curr_screenshots_paths\n",
    "            curr_reward           = self.game_controls.curr_reward\n",
    "            end_game              = self.game_controls.end_game\n",
    "#             curr_state           = self.preprocess_and_stack_images(curr_game_imgs_paths)\n",
    "\n",
    "            '''If the current state is not terminal i.e. not end_game'''\n",
    "            while not end_game: \n",
    "                action_to_be_taken = self.epsilon_greedy_policy_for_action(curr_state_imgs_paths)\n",
    "                next_state_imgs_paths, end_game, start_training_gap_period = self.add_experiences_to_buffers_after_running_game_for_one_step(action_to_be_taken, curr_state_imgs_paths)\n",
    "                curr_state_imgs_paths = next_state_imgs_paths\n",
    "\n",
    "                '''Train the model on random samples from both the experience buffers'''\n",
    "                self.adjust_buffer_sample_rate(epoch)\n",
    "                buffer_1_samples, buffer_2_samples = self.sample_mini_batches_from_experience_buffers()\n",
    "                loss = self.train_step(buffer_1_samples + buffer_2_samples)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "def train_network():\n",
    "    game_controls = Game_functions()\n",
    "    curr_game_imgs_, curr_reward, end_game = game_controls.curr_screenshot_path, game_controls.curr_reward, game_controls.end_game\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
